{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "## SR\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML \n",
    "from __future__ import print_function, division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdata = pd.read_csv('data.csv') #Three stocks (R,X_s,X_b) Without predictors\n",
    "mdata = np.array(mdata[['r','xs','xb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "38\n"
     ]
    }
   ],
   "source": [
    "#hyperparams\n",
    "\n",
    "num_epochs = 1000\n",
    "series_length = 50\n",
    "total_series_length = 241-series_length\n",
    "batch_size = 5\n",
    "truncated_backprop_length = series_length//batch_size\n",
    "print(truncated_backprop_length)\n",
    "state_size = 4\n",
    "num_classes = 1\n",
    "echo_step = 3\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_stocks = 3\n",
    "print(total_series_length//batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Reformat the data in such a way that the recurrent neural network can use it\n",
    "# The dataset is nothing more than a mini batch of multiple time stamps\n",
    "# The labels is the same time series shifted a few places (depending on the RNN)\n",
    "\n",
    "def generateData():\n",
    "    begin_idx = randint(0,total_series_length)\n",
    "    x = mdata.transpose()\n",
    "    x = x[0:3,begin_idx:begin_idx+series_length]\n",
    "    #shift 3 steps to the left\n",
    "    y = np.roll(x, echo_step, axis=1)\n",
    "    #padd beginning 3 values with 0\n",
    "    y[:,0:echo_step] = 0\n",
    "    #Gives a new shape to an array without changing its data.\n",
    "    #The reshaping takes the whole dataset and puts it into a matrix, \n",
    "    #that later will be sliced up into these mini-batches.\n",
    "    x = x.reshape((num_stocks, batch_size, -1))  # The first index changing slowest, subseries as rows\n",
    "    y = y.reshape((num_stocks, batch_size, -1))\n",
    "    return (x, y)\n",
    "\n",
    "data = generateData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#TensorFlow works by first building up a computational graph, that \n",
    "#specifies what operations will be done. The input and output of this graph\n",
    "#is typically multidimensional arrays, also known as tensors. \n",
    "#The graph, or parts of it can then be executed iteratively in a \n",
    "#session, this can either be done on the CPU, GPU or even a resource \n",
    "#on a remote server.\n",
    "\n",
    "#operations and tensors\n",
    "\n",
    "#The two basic TensorFlow data-structures that will be used in this \n",
    "#example are placeholders and variables. On each run the batch data \n",
    "#is fed to the placeholders, which are “starting nodes” of the \n",
    "#computational graph. Also the RNN-state is supplied in a placeholder, \n",
    "#which is saved from the output of the previous run.\n",
    "\n",
    "#Step 2 - Build the Model\n",
    "\n",
    "#datatype, shape (3,5,15) matrix, batch size shape for later\n",
    "batchX_placeholder = tf.placeholder(tf.float32, [num_stocks, batch_size, truncated_backprop_length])\n",
    "batchY_placeholder = tf.placeholder(tf.float32, [ num_stocks, batch_size, truncated_backprop_length])\n",
    "\n",
    "#and one for the RNN state, (3,5,4) \n",
    "init_state = tf.placeholder(tf.float32, [num_stocks, batch_size, state_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#The weights and biases of the network are declared as TensorFlow variables,\n",
    "#which makes them persistent across runs and enables them to be updated\n",
    "#incrementally for each batch.\n",
    "\n",
    "#3 layer recurrent net, one hidden state\n",
    "\n",
    "#randomly initialize weights\n",
    "W = tf.Variable(np.random.rand(num_stocks, state_size+1, state_size), dtype=tf.float32)\n",
    "#anchor, improves convergance, matrix of 0s \n",
    "b = tf.Variable(np.zeros((num_stocks,1,state_size)), dtype=tf.float32)\n",
    "\n",
    "W2 = tf.Variable(np.random.rand(num_stocks, state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((num_stocks, 1,num_classes)), dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now it’s time to build the part of the graph that resembles the actual RNN computation, \n",
    "#first we want to split the batch data into adjacent time-steps.\n",
    "\n",
    "# Unpack columns\n",
    "#Unpacks the given dimension of a rank-R tensor into rank-(R-1) tensors.\n",
    "#so a bunch of arrays, 1 batch per time step\n",
    "inputs_series = tf.unstack(batchX_placeholder, axis=2)\n",
    "labels_series = tf.unstack(batchY_placeholder, axis=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Forward pass\n",
    "#state placeholder\n",
    "current_state = init_state\n",
    "#series of states through time\n",
    "states_series = []\n",
    "\n",
    "#for each set of inputs\n",
    "#forward pass through the network to get new state value\n",
    "#store all states in memory\n",
    "for current_input in inputs_series:\n",
    "    #format input\n",
    "    current_input = tf.reshape(current_input, [num_stocks,batch_size, 1])\n",
    "    #mix both state and input data\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],axis=2)  # Increasing number of columns\n",
    "    #perform matrix multiplication between weights and input, add bias\n",
    "    #squash with a nonlinearity, for probabiolity value\n",
    "\n",
    "    # perform matrix multiplication\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated,W) + b)  # Broadcasted addition\n",
    "    #store the state in memory\n",
    "    states_series.append(next_state)\n",
    "    #set current state to next one\n",
    "    current_state = next_state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-04dea9452f3f>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels_series\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "print(labels_series.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n"
     ]
    }
   ],
   "source": [
    "#calculate loss\n",
    "#second part of forward pass\n",
    "#logits short for logistic transform\n",
    "logits_series = [tf.matmul(state, W2) + b2 for state in states_series] #Broadcasted addition\n",
    "#apply softmax nonlinearity for output probability (No Softmax here because i want continuous output)\n",
    "predictions_series = logits_series\n",
    "print(len(predictions_series))\n",
    "\n",
    "#measure loss, calculate softmax again on logits, then compute cross entropy\n",
    "#measures the difference between two probability distributions\n",
    "#this will return A Tensor of the same shape as labels and of the same type as logits \n",
    "#with the softmax cross entropy loss.\n",
    "losses = [ abs(tf.reshape(logits,(num_stocks,-1)) - labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "# [tf.nn.sparse_softmax_cross_entropy_with_logits(logits=logits, labels=labels) for logits, labels in zip(logits_series,labels_series)]\n",
    "#computes average, one value\n",
    "# total_loss = np.mean(losses)\n",
    "total_loss = tf.reduce_mean(tf.reduce_mean(losses))\n",
    "#use adagrad to minimize with .3 learning rate\n",
    "#minimize it with adagrad, not SGD\n",
    "#One downside of SGD is that it is sensitive to\n",
    "#the learning rate hyper-parameter. When the data are sparse and features have\n",
    "#different frequencies, a single learning rate for every weight update can have\n",
    "#exponential regret.\n",
    "#Some features can be extremely useful and informative to an optimization problem but \n",
    "#they may not show up in most of the training instances or data. If, when they do show up, \n",
    "#they are weighted equally in terms of learning rate as a feature that has shown up hundreds \n",
    "#of times we are practically saying that the influence of such features means nothing in the \n",
    "#overall optimization. it's impact per step in the stochastic gradient descent will be so small \n",
    "#that it can practically be discounted). To counter this, AdaGrad makes it such that features \n",
    "#that are more sparse in the data have a higher learning rate which translates into a larger \n",
    "#update for that feature\n",
    "#sparse features can be very useful.\n",
    "#Each feature has a different learning rate which is adaptable. \n",
    "#gives voice to the little guy who matters a lot\n",
    "#weights that receive high gradients will have their effective learning rate reduced, \n",
    "#while weights that receive small or infrequent updates will have their effective learning rate increased. \n",
    "#great paper http://seed.ucsd.edu/mediawiki/images/6/6a/Adagrad.pdf\n",
    "train_step = tf.train.AdagradOptimizer(0.3).minimize(total_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#visualizer\n",
    "def plot(loss_list, predictions_series, batchX, batchY):\n",
    "    plt.subplot(2, 3, 1)\n",
    "    plt.cla()\n",
    "    plt.plot(loss_list)\n",
    "\n",
    "    for batch_series_idx in range(5):\n",
    "        one_hot_output_series = np.array(predictions_series)[:, batch_series_idx, :]\n",
    "        single_output_series = np.array([(1 if out[0] < 0.5 else 0) for out in one_hot_output_series])\n",
    "\n",
    "        plt.subplot(2, 3, batch_series_idx + 2)\n",
    "        plt.cla()\n",
    "        plt.axis([0, truncated_backprop_length, 0, 2])\n",
    "        left_offset = range(truncated_backprop_length)\n",
    "        plt.bar(left_offset, batchX[batch_series_idx, :], width=1, color=\"blue\")\n",
    "        plt.bar(left_offset, batchY[batch_series_idx, :] * 0.5, width=1, color=\"red\")\n",
    "        plt.bar(left_offset, single_output_series * 0.3, width=1, color=\"green\")\n",
    "\n",
    "    plt.draw()\n",
    "    plt.pause(0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.figure.Figure at 0x250b94cfcc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 0\n",
      "New data, epoch 1\n",
      "New data, epoch 2\n",
      "New data, epoch 3\n",
      "New data, epoch 4\n",
      "New data, epoch 5\n",
      "New data, epoch 6\n",
      "New data, epoch 7\n",
      "New data, epoch 8\n",
      "New data, epoch 9\n",
      "New data, epoch 10\n",
      "New data, epoch 11\n",
      "New data, epoch 12\n",
      "New data, epoch 13\n",
      "New data, epoch 14\n",
      "New data, epoch 15\n",
      "New data, epoch 16\n",
      "New data, epoch 17\n",
      "New data, epoch 18\n",
      "New data, epoch 19\n",
      "New data, epoch 20\n",
      "New data, epoch 21\n",
      "New data, epoch 22\n",
      "New data, epoch 23\n",
      "New data, epoch 24\n",
      "New data, epoch 25\n",
      "New data, epoch 26\n",
      "New data, epoch 27\n",
      "New data, epoch 28\n",
      "New data, epoch 29\n",
      "New data, epoch 30\n",
      "New data, epoch 31\n",
      "New data, epoch 32\n",
      "New data, epoch 33\n",
      "New data, epoch 34\n",
      "New data, epoch 35\n",
      "New data, epoch 36\n",
      "New data, epoch 37\n",
      "New data, epoch 38\n",
      "New data, epoch 39\n",
      "New data, epoch 40\n",
      "New data, epoch 41\n",
      "New data, epoch 42\n",
      "New data, epoch 43\n",
      "New data, epoch 44\n",
      "New data, epoch 45\n",
      "New data, epoch 46\n",
      "New data, epoch 47\n",
      "New data, epoch 48\n",
      "New data, epoch 49\n",
      "New data, epoch 50\n",
      "New data, epoch 51\n",
      "New data, epoch 52\n",
      "New data, epoch 53\n",
      "New data, epoch 54\n",
      "New data, epoch 55\n",
      "New data, epoch 56\n",
      "New data, epoch 57\n",
      "New data, epoch 58\n",
      "New data, epoch 59\n",
      "New data, epoch 60\n",
      "New data, epoch 61\n",
      "New data, epoch 62\n",
      "New data, epoch 63\n",
      "New data, epoch 64\n",
      "New data, epoch 65\n",
      "New data, epoch 66\n",
      "New data, epoch 67\n",
      "New data, epoch 68\n",
      "New data, epoch 69\n",
      "New data, epoch 70\n",
      "New data, epoch 71\n",
      "New data, epoch 72\n",
      "New data, epoch 73\n",
      "New data, epoch 74\n",
      "New data, epoch 75\n",
      "New data, epoch 76\n",
      "New data, epoch 77\n",
      "New data, epoch 78\n",
      "New data, epoch 79\n",
      "New data, epoch 80\n",
      "New data, epoch 81\n",
      "New data, epoch 82\n",
      "New data, epoch 83\n",
      "New data, epoch 84\n",
      "New data, epoch 85\n",
      "New data, epoch 86\n",
      "New data, epoch 87\n",
      "New data, epoch 88\n",
      "New data, epoch 89\n",
      "New data, epoch 90\n",
      "New data, epoch 91\n",
      "New data, epoch 92\n",
      "New data, epoch 93\n",
      "New data, epoch 94\n",
      "New data, epoch 95\n",
      "New data, epoch 96\n",
      "New data, epoch 97\n",
      "New data, epoch 98\n",
      "New data, epoch 99\n",
      "New data, epoch 100\n",
      "New data, epoch 101\n",
      "New data, epoch 102\n",
      "New data, epoch 103\n",
      "New data, epoch 104\n",
      "New data, epoch 105\n",
      "New data, epoch 106\n",
      "New data, epoch 107\n",
      "New data, epoch 108\n",
      "New data, epoch 109\n",
      "New data, epoch 110\n",
      "New data, epoch 111\n",
      "New data, epoch 112\n",
      "New data, epoch 113\n",
      "New data, epoch 114\n",
      "New data, epoch 115\n",
      "New data, epoch 116\n",
      "New data, epoch 117\n",
      "New data, epoch 118\n",
      "New data, epoch 119\n",
      "New data, epoch 120\n",
      "New data, epoch 121\n",
      "New data, epoch 122\n",
      "New data, epoch 123\n",
      "New data, epoch 124\n",
      "New data, epoch 125\n",
      "New data, epoch 126\n",
      "New data, epoch 127\n",
      "New data, epoch 128\n",
      "New data, epoch 129\n",
      "New data, epoch 130\n",
      "New data, epoch 131\n",
      "New data, epoch 132\n",
      "New data, epoch 133\n",
      "New data, epoch 134\n",
      "New data, epoch 135\n",
      "New data, epoch 136\n",
      "New data, epoch 137\n",
      "New data, epoch 138\n",
      "New data, epoch 139\n",
      "New data, epoch 140\n",
      "New data, epoch 141\n",
      "New data, epoch 142\n",
      "New data, epoch 143\n",
      "New data, epoch 144\n",
      "New data, epoch 145\n",
      "New data, epoch 146\n",
      "New data, epoch 147\n",
      "New data, epoch 148\n",
      "New data, epoch 149\n",
      "New data, epoch 150\n",
      "New data, epoch 151\n",
      "New data, epoch 152\n",
      "New data, epoch 153\n",
      "New data, epoch 154\n",
      "New data, epoch 155\n",
      "New data, epoch 156\n",
      "New data, epoch 157\n",
      "New data, epoch 158\n",
      "New data, epoch 159\n",
      "New data, epoch 160\n",
      "New data, epoch 161\n",
      "New data, epoch 162\n",
      "New data, epoch 163\n",
      "New data, epoch 164\n",
      "New data, epoch 165\n",
      "New data, epoch 166\n",
      "New data, epoch 167\n",
      "New data, epoch 168\n",
      "New data, epoch 169\n",
      "New data, epoch 170\n",
      "New data, epoch 171\n",
      "New data, epoch 172\n",
      "New data, epoch 173\n",
      "New data, epoch 174\n",
      "New data, epoch 175\n",
      "New data, epoch 176\n",
      "New data, epoch 177\n",
      "New data, epoch 178\n",
      "New data, epoch 179\n",
      "New data, epoch 180\n",
      "New data, epoch 181\n",
      "New data, epoch 182\n",
      "New data, epoch 183\n",
      "New data, epoch 184\n",
      "New data, epoch 185\n",
      "New data, epoch 186\n",
      "New data, epoch 187\n",
      "New data, epoch 188\n",
      "New data, epoch 189\n",
      "New data, epoch 190\n",
      "New data, epoch 191\n",
      "New data, epoch 192\n",
      "New data, epoch 193\n",
      "New data, epoch 194\n",
      "New data, epoch 195\n",
      "New data, epoch 196\n",
      "New data, epoch 197\n",
      "New data, epoch 198\n",
      "New data, epoch 199\n",
      "New data, epoch 200\n",
      "New data, epoch 201\n",
      "New data, epoch 202\n",
      "New data, epoch 203\n",
      "New data, epoch 204\n",
      "New data, epoch 205\n",
      "New data, epoch 206\n",
      "New data, epoch 207\n",
      "New data, epoch 208\n",
      "New data, epoch 209\n",
      "New data, epoch 210\n",
      "New data, epoch 211\n",
      "New data, epoch 212\n",
      "New data, epoch 213\n",
      "New data, epoch 214\n",
      "New data, epoch 215\n",
      "New data, epoch 216\n",
      "New data, epoch 217\n",
      "New data, epoch 218\n",
      "New data, epoch 219\n",
      "New data, epoch 220\n",
      "New data, epoch 221\n",
      "New data, epoch 222\n",
      "New data, epoch 223\n",
      "New data, epoch 224\n",
      "New data, epoch 225\n",
      "New data, epoch 226\n",
      "New data, epoch 227\n",
      "New data, epoch 228\n",
      "New data, epoch 229\n",
      "New data, epoch 230\n",
      "New data, epoch 231\n",
      "New data, epoch 232\n",
      "New data, epoch 233\n",
      "New data, epoch 234\n",
      "New data, epoch 235\n",
      "New data, epoch 236\n",
      "New data, epoch 237\n",
      "New data, epoch 238\n",
      "New data, epoch 239\n",
      "New data, epoch 240\n",
      "New data, epoch 241\n",
      "New data, epoch 242\n",
      "New data, epoch 243\n",
      "New data, epoch 244\n",
      "New data, epoch 245\n",
      "New data, epoch 246\n",
      "New data, epoch 247\n",
      "New data, epoch 248\n",
      "New data, epoch 249\n",
      "New data, epoch 250\n",
      "New data, epoch 251\n",
      "New data, epoch 252\n",
      "New data, epoch 253\n",
      "New data, epoch 254\n",
      "New data, epoch 255\n",
      "New data, epoch 256\n",
      "New data, epoch 257\n",
      "New data, epoch 258\n",
      "New data, epoch 259\n",
      "New data, epoch 260\n",
      "New data, epoch 261\n",
      "New data, epoch 262\n",
      "New data, epoch 263\n",
      "New data, epoch 264\n",
      "New data, epoch 265\n",
      "New data, epoch 266\n",
      "New data, epoch 267\n",
      "New data, epoch 268\n",
      "New data, epoch 269\n",
      "New data, epoch 270\n",
      "New data, epoch 271\n",
      "New data, epoch 272\n",
      "New data, epoch 273\n",
      "New data, epoch 274\n",
      "New data, epoch 275\n",
      "New data, epoch 276\n",
      "New data, epoch 277\n",
      "New data, epoch 278\n",
      "New data, epoch 279\n",
      "New data, epoch 280\n",
      "New data, epoch 281\n",
      "New data, epoch 282\n",
      "New data, epoch 283\n",
      "New data, epoch 284\n",
      "New data, epoch 285\n",
      "New data, epoch 286\n",
      "New data, epoch 287\n",
      "New data, epoch 288\n",
      "New data, epoch 289\n",
      "New data, epoch 290\n",
      "New data, epoch 291\n",
      "New data, epoch 292\n",
      "New data, epoch 293\n",
      "New data, epoch 294\n",
      "New data, epoch 295\n",
      "New data, epoch 296\n",
      "New data, epoch 297\n",
      "New data, epoch 298\n",
      "New data, epoch 299\n",
      "New data, epoch 300\n",
      "New data, epoch 301\n",
      "New data, epoch 302\n",
      "New data, epoch 303\n",
      "New data, epoch 304\n",
      "New data, epoch 305\n",
      "New data, epoch 306\n",
      "New data, epoch 307\n",
      "New data, epoch 308\n",
      "New data, epoch 309\n",
      "New data, epoch 310\n",
      "New data, epoch 311\n",
      "New data, epoch 312\n",
      "New data, epoch 313\n",
      "New data, epoch 314\n",
      "New data, epoch 315\n",
      "New data, epoch 316\n",
      "New data, epoch 317\n",
      "New data, epoch 318\n",
      "New data, epoch 319\n",
      "New data, epoch 320\n",
      "New data, epoch 321\n",
      "New data, epoch 322\n",
      "New data, epoch 323\n",
      "New data, epoch 324\n",
      "New data, epoch 325\n",
      "New data, epoch 326\n",
      "New data, epoch 327\n",
      "New data, epoch 328\n",
      "New data, epoch 329\n",
      "New data, epoch 330\n",
      "New data, epoch 331\n",
      "New data, epoch 332\n",
      "New data, epoch 333\n",
      "New data, epoch 334\n",
      "New data, epoch 335\n",
      "New data, epoch 336\n",
      "New data, epoch 337\n",
      "New data, epoch 338\n",
      "New data, epoch 339\n",
      "New data, epoch 340\n",
      "New data, epoch 341\n",
      "New data, epoch 342\n",
      "New data, epoch 343\n",
      "New data, epoch 344\n",
      "New data, epoch 345\n",
      "New data, epoch 346\n",
      "New data, epoch 347\n",
      "New data, epoch 348\n",
      "New data, epoch 349\n",
      "New data, epoch 350\n",
      "New data, epoch 351\n",
      "New data, epoch 352\n",
      "New data, epoch 353\n",
      "New data, epoch 354\n",
      "New data, epoch 355\n",
      "New data, epoch 356\n",
      "New data, epoch 357\n",
      "New data, epoch 358\n",
      "New data, epoch 359\n",
      "New data, epoch 360\n",
      "New data, epoch 361\n",
      "New data, epoch 362\n",
      "New data, epoch 363\n",
      "New data, epoch 364\n",
      "New data, epoch 365\n",
      "New data, epoch 366\n",
      "New data, epoch 367\n",
      "New data, epoch 368\n",
      "New data, epoch 369\n",
      "New data, epoch 370\n",
      "New data, epoch 371\n",
      "New data, epoch 372\n",
      "New data, epoch 373\n",
      "New data, epoch 374\n",
      "New data, epoch 375\n",
      "New data, epoch 376\n",
      "New data, epoch 377\n",
      "New data, epoch 378\n",
      "New data, epoch 379\n",
      "New data, epoch 380\n",
      "New data, epoch 381\n",
      "New data, epoch 382\n",
      "New data, epoch 383\n",
      "New data, epoch 384\n",
      "New data, epoch 385\n",
      "New data, epoch 386\n",
      "New data, epoch 387\n",
      "New data, epoch 388\n",
      "New data, epoch 389\n",
      "New data, epoch 390\n",
      "New data, epoch 391\n",
      "New data, epoch 392\n",
      "New data, epoch 393\n",
      "New data, epoch 394\n",
      "New data, epoch 395\n",
      "New data, epoch 396\n",
      "New data, epoch 397\n",
      "New data, epoch 398\n",
      "New data, epoch 399\n",
      "New data, epoch 400\n",
      "New data, epoch 401\n",
      "New data, epoch 402\n",
      "New data, epoch 403\n",
      "New data, epoch 404\n",
      "New data, epoch 405\n",
      "New data, epoch 406\n",
      "New data, epoch 407\n",
      "New data, epoch 408\n",
      "New data, epoch 409\n",
      "New data, epoch 410\n",
      "New data, epoch 411\n",
      "New data, epoch 412\n",
      "New data, epoch 413\n",
      "New data, epoch 414\n",
      "New data, epoch 415\n",
      "New data, epoch 416\n",
      "New data, epoch 417\n",
      "New data, epoch 418\n",
      "New data, epoch 419\n",
      "New data, epoch 420\n",
      "New data, epoch 421\n",
      "New data, epoch 422\n",
      "New data, epoch 423\n",
      "New data, epoch 424\n",
      "New data, epoch 425\n",
      "New data, epoch 426\n",
      "New data, epoch 427\n",
      "New data, epoch 428\n",
      "New data, epoch 429\n",
      "New data, epoch 430\n",
      "New data, epoch 431\n",
      "New data, epoch 432\n",
      "New data, epoch 433\n",
      "New data, epoch 434\n",
      "New data, epoch 435\n",
      "New data, epoch 436\n",
      "New data, epoch 437\n",
      "New data, epoch 438\n",
      "New data, epoch 439\n",
      "New data, epoch 440\n",
      "New data, epoch 441\n",
      "New data, epoch 442\n",
      "New data, epoch 443\n",
      "New data, epoch 444\n",
      "New data, epoch 445\n",
      "New data, epoch 446\n",
      "New data, epoch 447\n",
      "New data, epoch 448\n",
      "New data, epoch 449\n",
      "New data, epoch 450\n",
      "New data, epoch 451\n",
      "New data, epoch 452\n",
      "New data, epoch 453\n",
      "New data, epoch 454\n",
      "New data, epoch 455\n",
      "New data, epoch 456\n",
      "New data, epoch 457\n",
      "New data, epoch 458\n",
      "New data, epoch 459\n",
      "New data, epoch 460\n",
      "New data, epoch 461\n",
      "New data, epoch 462\n",
      "New data, epoch 463\n",
      "New data, epoch 464\n",
      "New data, epoch 465\n",
      "New data, epoch 466\n",
      "New data, epoch 467\n",
      "New data, epoch 468\n",
      "New data, epoch 469\n",
      "New data, epoch 470\n",
      "New data, epoch 471\n",
      "New data, epoch 472\n",
      "New data, epoch 473\n",
      "New data, epoch 474\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 475\n",
      "New data, epoch 476\n",
      "New data, epoch 477\n",
      "New data, epoch 478\n",
      "New data, epoch 479\n",
      "New data, epoch 480\n",
      "New data, epoch 481\n",
      "New data, epoch 482\n",
      "New data, epoch 483\n",
      "New data, epoch 484\n",
      "New data, epoch 485\n",
      "New data, epoch 486\n",
      "New data, epoch 487\n",
      "New data, epoch 488\n",
      "New data, epoch 489\n",
      "New data, epoch 490\n",
      "New data, epoch 491\n",
      "New data, epoch 492\n",
      "New data, epoch 493\n",
      "New data, epoch 494\n",
      "New data, epoch 495\n",
      "New data, epoch 496\n",
      "New data, epoch 497\n",
      "New data, epoch 498\n",
      "New data, epoch 499\n",
      "New data, epoch 500\n",
      "New data, epoch 501\n",
      "New data, epoch 502\n",
      "New data, epoch 503\n",
      "New data, epoch 504\n",
      "New data, epoch 505\n",
      "New data, epoch 506\n",
      "New data, epoch 507\n",
      "New data, epoch 508\n",
      "New data, epoch 509\n",
      "New data, epoch 510\n",
      "New data, epoch 511\n",
      "New data, epoch 512\n",
      "New data, epoch 513\n",
      "New data, epoch 514\n",
      "New data, epoch 515\n",
      "New data, epoch 516\n",
      "New data, epoch 517\n",
      "New data, epoch 518\n",
      "New data, epoch 519\n",
      "New data, epoch 520\n",
      "New data, epoch 521\n",
      "New data, epoch 522\n",
      "New data, epoch 523\n",
      "New data, epoch 524\n",
      "New data, epoch 525\n",
      "New data, epoch 526\n",
      "New data, epoch 527\n",
      "New data, epoch 528\n",
      "New data, epoch 529\n",
      "New data, epoch 530\n",
      "New data, epoch 531\n",
      "New data, epoch 532\n",
      "New data, epoch 533\n",
      "New data, epoch 534\n",
      "New data, epoch 535\n",
      "New data, epoch 536\n",
      "New data, epoch 537\n",
      "New data, epoch 538\n",
      "New data, epoch 539\n",
      "New data, epoch 540\n",
      "New data, epoch 541\n",
      "New data, epoch 542\n",
      "New data, epoch 543\n",
      "New data, epoch 544\n",
      "New data, epoch 545\n",
      "New data, epoch 546\n",
      "New data, epoch 547\n",
      "New data, epoch 548\n",
      "New data, epoch 549\n",
      "New data, epoch 550\n",
      "New data, epoch 551\n",
      "New data, epoch 552\n",
      "New data, epoch 553\n",
      "New data, epoch 554\n",
      "New data, epoch 555\n",
      "New data, epoch 556\n",
      "New data, epoch 557\n",
      "New data, epoch 558\n",
      "New data, epoch 559\n",
      "New data, epoch 560\n",
      "New data, epoch 561\n",
      "New data, epoch 562\n",
      "New data, epoch 563\n",
      "New data, epoch 564\n",
      "New data, epoch 565\n",
      "New data, epoch 566\n",
      "New data, epoch 567\n",
      "New data, epoch 568\n",
      "New data, epoch 569\n",
      "New data, epoch 570\n",
      "New data, epoch 571\n",
      "New data, epoch 572\n",
      "New data, epoch 573\n",
      "New data, epoch 574\n",
      "New data, epoch 575\n",
      "New data, epoch 576\n",
      "New data, epoch 577\n",
      "New data, epoch 578\n",
      "New data, epoch 579\n",
      "New data, epoch 580\n",
      "New data, epoch 581\n",
      "New data, epoch 582\n",
      "New data, epoch 583\n",
      "New data, epoch 584\n",
      "New data, epoch 585\n",
      "New data, epoch 586\n",
      "New data, epoch 587\n",
      "New data, epoch 588\n",
      "New data, epoch 589\n",
      "New data, epoch 590\n",
      "New data, epoch 591\n",
      "New data, epoch 592\n",
      "New data, epoch 593\n",
      "New data, epoch 594\n",
      "New data, epoch 595\n",
      "New data, epoch 596\n",
      "New data, epoch 597\n",
      "New data, epoch 598\n",
      "New data, epoch 599\n",
      "New data, epoch 600\n",
      "New data, epoch 601\n",
      "New data, epoch 602\n",
      "New data, epoch 603\n",
      "New data, epoch 604\n",
      "New data, epoch 605\n",
      "New data, epoch 606\n",
      "New data, epoch 607\n",
      "New data, epoch 608\n",
      "New data, epoch 609\n",
      "New data, epoch 610\n",
      "New data, epoch 611\n",
      "New data, epoch 612\n",
      "New data, epoch 613\n",
      "New data, epoch 614\n",
      "New data, epoch 615\n",
      "New data, epoch 616\n",
      "New data, epoch 617\n",
      "New data, epoch 618\n",
      "New data, epoch 619\n",
      "New data, epoch 620\n",
      "New data, epoch 621\n",
      "New data, epoch 622\n",
      "New data, epoch 623\n",
      "New data, epoch 624\n",
      "New data, epoch 625\n",
      "New data, epoch 626\n",
      "New data, epoch 627\n",
      "New data, epoch 628\n",
      "New data, epoch 629\n",
      "New data, epoch 630\n",
      "New data, epoch 631\n",
      "New data, epoch 632\n",
      "New data, epoch 633\n",
      "New data, epoch 634\n",
      "New data, epoch 635\n",
      "New data, epoch 636\n",
      "New data, epoch 637\n",
      "New data, epoch 638\n",
      "New data, epoch 639\n",
      "New data, epoch 640\n",
      "New data, epoch 641\n",
      "New data, epoch 642\n",
      "New data, epoch 643\n",
      "New data, epoch 644\n",
      "New data, epoch 645\n",
      "New data, epoch 646\n",
      "New data, epoch 647\n",
      "New data, epoch 648\n",
      "New data, epoch 649\n",
      "New data, epoch 650\n",
      "New data, epoch 651\n",
      "New data, epoch 652\n",
      "New data, epoch 653\n",
      "New data, epoch 654\n",
      "New data, epoch 655\n",
      "New data, epoch 656\n",
      "New data, epoch 657\n",
      "New data, epoch 658\n",
      "New data, epoch 659\n",
      "New data, epoch 660\n",
      "New data, epoch 661\n",
      "New data, epoch 662\n",
      "New data, epoch 663\n",
      "New data, epoch 664\n",
      "New data, epoch 665\n",
      "New data, epoch 666\n",
      "New data, epoch 667\n",
      "New data, epoch 668\n",
      "New data, epoch 669\n",
      "New data, epoch 670\n",
      "New data, epoch 671\n",
      "New data, epoch 672\n",
      "New data, epoch 673\n",
      "New data, epoch 674\n",
      "New data, epoch 675\n",
      "New data, epoch 676\n",
      "New data, epoch 677\n",
      "New data, epoch 678\n",
      "New data, epoch 679\n",
      "New data, epoch 680\n",
      "New data, epoch 681\n",
      "New data, epoch 682\n",
      "New data, epoch 683\n",
      "New data, epoch 684\n",
      "New data, epoch 685\n",
      "New data, epoch 686\n",
      "New data, epoch 687\n",
      "New data, epoch 688\n",
      "New data, epoch 689\n",
      "New data, epoch 690\n",
      "New data, epoch 691\n",
      "New data, epoch 692\n",
      "New data, epoch 693\n",
      "New data, epoch 694\n",
      "New data, epoch 695\n",
      "New data, epoch 696\n",
      "New data, epoch 697\n",
      "New data, epoch 698\n",
      "New data, epoch 699\n",
      "New data, epoch 700\n",
      "New data, epoch 701\n",
      "New data, epoch 702\n",
      "New data, epoch 703\n",
      "New data, epoch 704\n",
      "New data, epoch 705\n",
      "New data, epoch 706\n",
      "New data, epoch 707\n",
      "New data, epoch 708\n",
      "New data, epoch 709\n",
      "New data, epoch 710\n",
      "New data, epoch 711\n",
      "New data, epoch 712\n",
      "New data, epoch 713\n",
      "New data, epoch 714\n",
      "New data, epoch 715\n",
      "New data, epoch 716\n",
      "New data, epoch 717\n",
      "New data, epoch 718\n",
      "New data, epoch 719\n",
      "New data, epoch 720\n",
      "New data, epoch 721\n",
      "New data, epoch 722\n",
      "New data, epoch 723\n",
      "New data, epoch 724\n",
      "New data, epoch 725\n",
      "New data, epoch 726\n",
      "New data, epoch 727\n",
      "New data, epoch 728\n",
      "New data, epoch 729\n",
      "New data, epoch 730\n",
      "New data, epoch 731\n",
      "New data, epoch 732\n",
      "New data, epoch 733\n",
      "New data, epoch 734\n",
      "New data, epoch 735\n",
      "New data, epoch 736\n",
      "New data, epoch 737\n",
      "New data, epoch 738\n",
      "New data, epoch 739\n",
      "New data, epoch 740\n",
      "New data, epoch 741\n",
      "New data, epoch 742\n",
      "New data, epoch 743\n",
      "New data, epoch 744\n",
      "New data, epoch 745\n",
      "New data, epoch 746\n",
      "New data, epoch 747\n",
      "New data, epoch 748\n",
      "New data, epoch 749\n",
      "New data, epoch 750\n",
      "New data, epoch 751\n",
      "New data, epoch 752\n",
      "New data, epoch 753\n",
      "New data, epoch 754\n",
      "New data, epoch 755\n",
      "New data, epoch 756\n",
      "New data, epoch 757\n",
      "New data, epoch 758\n",
      "New data, epoch 759\n",
      "New data, epoch 760\n",
      "New data, epoch 761\n",
      "New data, epoch 762\n",
      "New data, epoch 763\n",
      "New data, epoch 764\n",
      "New data, epoch 765\n",
      "New data, epoch 766\n",
      "New data, epoch 767\n",
      "New data, epoch 768\n",
      "New data, epoch 769\n",
      "New data, epoch 770\n",
      "New data, epoch 771\n",
      "New data, epoch 772\n",
      "New data, epoch 773\n",
      "New data, epoch 774\n",
      "New data, epoch 775\n",
      "New data, epoch 776\n",
      "New data, epoch 777\n",
      "New data, epoch 778\n",
      "New data, epoch 779\n",
      "New data, epoch 780\n",
      "New data, epoch 781\n",
      "New data, epoch 782\n",
      "New data, epoch 783\n",
      "New data, epoch 784\n",
      "New data, epoch 785\n",
      "New data, epoch 786\n",
      "New data, epoch 787\n",
      "New data, epoch 788\n",
      "New data, epoch 789\n",
      "New data, epoch 790\n",
      "New data, epoch 791\n",
      "New data, epoch 792\n",
      "New data, epoch 793\n",
      "New data, epoch 794\n",
      "New data, epoch 795\n",
      "New data, epoch 796\n",
      "New data, epoch 797\n",
      "New data, epoch 798\n",
      "New data, epoch 799\n",
      "New data, epoch 800\n",
      "New data, epoch 801\n",
      "New data, epoch 802\n",
      "New data, epoch 803\n",
      "New data, epoch 804\n",
      "New data, epoch 805\n",
      "New data, epoch 806\n",
      "New data, epoch 807\n",
      "New data, epoch 808\n",
      "New data, epoch 809\n",
      "New data, epoch 810\n",
      "New data, epoch 811\n",
      "New data, epoch 812\n",
      "New data, epoch 813\n",
      "New data, epoch 814\n",
      "New data, epoch 815\n",
      "New data, epoch 816\n",
      "New data, epoch 817\n",
      "New data, epoch 818\n",
      "New data, epoch 819\n",
      "New data, epoch 820\n",
      "New data, epoch 821\n",
      "New data, epoch 822\n",
      "New data, epoch 823\n",
      "New data, epoch 824\n",
      "New data, epoch 825\n",
      "New data, epoch 826\n",
      "New data, epoch 827\n",
      "New data, epoch 828\n",
      "New data, epoch 829\n",
      "New data, epoch 830\n",
      "New data, epoch 831\n",
      "New data, epoch 832\n",
      "New data, epoch 833\n",
      "New data, epoch 834\n",
      "New data, epoch 835\n",
      "New data, epoch 836\n",
      "New data, epoch 837\n",
      "New data, epoch 838\n",
      "New data, epoch 839\n",
      "New data, epoch 840\n",
      "New data, epoch 841\n",
      "New data, epoch 842\n",
      "New data, epoch 843\n",
      "New data, epoch 844\n",
      "New data, epoch 845\n",
      "New data, epoch 846\n",
      "New data, epoch 847\n",
      "New data, epoch 848\n",
      "New data, epoch 849\n",
      "New data, epoch 850\n",
      "New data, epoch 851\n",
      "New data, epoch 852\n",
      "New data, epoch 853\n",
      "New data, epoch 854\n",
      "New data, epoch 855\n",
      "New data, epoch 856\n",
      "New data, epoch 857\n",
      "New data, epoch 858\n",
      "New data, epoch 859\n",
      "New data, epoch 860\n",
      "New data, epoch 861\n",
      "New data, epoch 862\n",
      "New data, epoch 863\n",
      "New data, epoch 864\n",
      "New data, epoch 865\n",
      "New data, epoch 866\n",
      "New data, epoch 867\n",
      "New data, epoch 868\n",
      "New data, epoch 869\n",
      "New data, epoch 870\n",
      "New data, epoch 871\n",
      "New data, epoch 872\n",
      "New data, epoch 873\n",
      "New data, epoch 874\n",
      "New data, epoch 875\n",
      "New data, epoch 876\n",
      "New data, epoch 877\n",
      "New data, epoch 878\n",
      "New data, epoch 879\n",
      "New data, epoch 880\n",
      "New data, epoch 881\n",
      "New data, epoch 882\n",
      "New data, epoch 883\n",
      "New data, epoch 884\n",
      "New data, epoch 885\n",
      "New data, epoch 886\n",
      "New data, epoch 887\n",
      "New data, epoch 888\n",
      "New data, epoch 889\n",
      "New data, epoch 890\n",
      "New data, epoch 891\n",
      "New data, epoch 892\n",
      "New data, epoch 893\n",
      "New data, epoch 894\n",
      "New data, epoch 895\n",
      "New data, epoch 896\n",
      "New data, epoch 897\n",
      "New data, epoch 898\n",
      "New data, epoch 899\n",
      "New data, epoch 900\n",
      "New data, epoch 901\n",
      "New data, epoch 902\n",
      "New data, epoch 903\n",
      "New data, epoch 904\n",
      "New data, epoch 905\n",
      "New data, epoch 906\n",
      "New data, epoch 907\n",
      "New data, epoch 908\n",
      "New data, epoch 909\n",
      "New data, epoch 910\n",
      "New data, epoch 911\n",
      "New data, epoch 912\n",
      "New data, epoch 913\n",
      "New data, epoch 914\n",
      "New data, epoch 915\n",
      "New data, epoch 916\n",
      "New data, epoch 917\n",
      "New data, epoch 918\n",
      "New data, epoch 919\n",
      "New data, epoch 920\n",
      "New data, epoch 921\n",
      "New data, epoch 922\n",
      "New data, epoch 923\n",
      "New data, epoch 924\n",
      "New data, epoch 925\n",
      "New data, epoch 926\n",
      "New data, epoch 927\n",
      "New data, epoch 928\n",
      "New data, epoch 929\n",
      "New data, epoch 930\n",
      "New data, epoch 931\n",
      "New data, epoch 932\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New data, epoch 933\n",
      "New data, epoch 934\n",
      "New data, epoch 935\n",
      "New data, epoch 936\n",
      "New data, epoch 937\n",
      "New data, epoch 938\n",
      "New data, epoch 939\n",
      "New data, epoch 940\n",
      "New data, epoch 941\n",
      "New data, epoch 942\n",
      "New data, epoch 943\n",
      "New data, epoch 944\n",
      "New data, epoch 945\n",
      "New data, epoch 946\n",
      "New data, epoch 947\n",
      "New data, epoch 948\n",
      "New data, epoch 949\n",
      "New data, epoch 950\n",
      "New data, epoch 951\n",
      "New data, epoch 952\n",
      "New data, epoch 953\n",
      "New data, epoch 954\n",
      "New data, epoch 955\n",
      "New data, epoch 956\n",
      "New data, epoch 957\n",
      "New data, epoch 958\n",
      "New data, epoch 959\n",
      "New data, epoch 960\n",
      "New data, epoch 961\n",
      "New data, epoch 962\n",
      "New data, epoch 963\n",
      "New data, epoch 964\n",
      "New data, epoch 965\n",
      "New data, epoch 966\n",
      "New data, epoch 967\n",
      "New data, epoch 968\n",
      "New data, epoch 969\n",
      "New data, epoch 970\n",
      "New data, epoch 971\n",
      "New data, epoch 972\n",
      "New data, epoch 973\n",
      "New data, epoch 974\n",
      "New data, epoch 975\n",
      "New data, epoch 976\n",
      "New data, epoch 977\n",
      "New data, epoch 978\n",
      "New data, epoch 979\n",
      "New data, epoch 980\n",
      "New data, epoch 981\n",
      "New data, epoch 982\n",
      "New data, epoch 983\n",
      "New data, epoch 984\n",
      "New data, epoch 985\n",
      "New data, epoch 986\n",
      "New data, epoch 987\n",
      "New data, epoch 988\n",
      "New data, epoch 989\n",
      "New data, epoch 990\n",
      "New data, epoch 991\n",
      "New data, epoch 992\n",
      "New data, epoch 993\n",
      "New data, epoch 994\n",
      "New data, epoch 995\n",
      "New data, epoch 996\n",
      "New data, epoch 997\n",
      "New data, epoch 998\n",
      "New data, epoch 999\n",
      "[[[-0.01063358]\n",
      "  [-0.01063221]\n",
      "  [-0.01044175]\n",
      "  [-0.01057679]\n",
      "  [-0.01048157]]\n",
      "\n",
      " [[ 0.00403775]\n",
      "  [ 0.00185746]\n",
      "  [ 0.00387104]\n",
      "  [ 0.00386764]\n",
      "  [ 0.00368509]]\n",
      "\n",
      " [[ 0.01490319]\n",
      "  [ 0.01470248]\n",
      "  [ 0.01459937]\n",
      "  [ 0.01528417]\n",
      "  [ 0.01493013]]]\n",
      "[[[ 0.00583367]\n",
      "  [-0.00123333]\n",
      "  [ 0.00280833]\n",
      "  [ 0.00069167]\n",
      "  [-0.00100167]]\n",
      "\n",
      " [[ 0.01442633]\n",
      "  [ 0.00487533]\n",
      "  [-0.05285933]\n",
      "  [ 0.02880133]\n",
      "  [ 0.03544067]]\n",
      "\n",
      " [[-0.00320767]\n",
      "  [-0.00462367]\n",
      "  [-0.00062133]\n",
      "  [-0.00745567]\n",
      "  [-0.00766833]]]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nIiI56P8DErrlKFEoHQQAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x250b9b68438>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#Step 3 Training the network\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    #interactive mode\n",
    "    plt.ion()\n",
    "    #initialize the figure\n",
    "    plt.figure()\n",
    "    #show the graph\n",
    "    plt.show()\n",
    "    #to show the loss decrease\n",
    "    loss_list = []\n",
    "    batch_idx = 0\n",
    "    \n",
    "    for epoch_idx in range(num_epochs):\n",
    "        #generate data at every epoch, batches run in epochs\n",
    "        x,y = generateData()\n",
    "        #initialize an empty hidden state\n",
    "        _current_state = np.zeros((num_stocks, batch_size, state_size))\n",
    "\n",
    "        print(\"New data, epoch\", epoch_idx)\n",
    "        #each batch\n",
    "\n",
    "        #starting and ending point per batch\n",
    "        #since weights reoccuer at every layer through time\n",
    "        #These layers will not be unrolled to the beginning of time, \n",
    "        #that would be too computationally expensive, and are therefore truncated \n",
    "        #at a limited number of time-steps\n",
    "            \n",
    "        batchX = x\n",
    "        batchY = y\n",
    "    \n",
    "        # run the computation graph, give it the values\n",
    "        # we calculated earlier\n",
    "        _total_loss, _train_step, _current_state, _predictions_series = sess.run(\n",
    "            [total_loss, train_step, current_state, predictions_series],\n",
    "            feed_dict={\n",
    "                batchX_placeholder:batchX,\n",
    "                batchY_placeholder:batchY,\n",
    "                init_state:_current_state\n",
    "            })\n",
    "        \n",
    "\n",
    "        batch_idx += 1\n",
    "        loss_list.append(_total_loss)\n",
    "#         if batch_idx%10 == 0:\n",
    "#             print(\"Step\",batch_idx, \"Loss\", _total_loss)\n",
    "#         plt.plot(loss_list, _predictions_series[0,:,:], batchX[1,:,:], batchY[1,:,:])\n",
    "\n",
    "print(_predictions_series[-1])\n",
    "print(batchY[:,:,9:10])\n",
    "plt.plot(loss_list)\n",
    "plt.ioff()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Build an reinforcement learning agent around the RNN\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
