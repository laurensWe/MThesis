{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Simulations and benchmarks\n",
    "\n",
    "- Simulation of the real data by CER, VAR and BVAR\n",
    "- Model-free benchmarks and the dynamic strategy of classical portfolio management"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Laurens\\Anaconda3\\lib\\site-packages\\statsmodels\\compat\\pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    }
   ],
   "source": [
    "# initialization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import math\n",
    "import scipy.stats as dist\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from statsmodels.tsa.api import VAR, DynamicVAR\n",
    "import statsmodels.api as sm\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Import real data \n",
    "mdata = pd.read_csv('data.csv') #Three stocks (R,X_s,X_b) Without predictors\n",
    "data = mdata[['r','xs','xb']]\n",
    "dates = mdata['Date']\n",
    "data.index = dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read written away simulated data\n",
    "# VAR, CER and , BVAR\n",
    "mdata = pd.read_excel('sim_data_CER.xlsx') #Three stocks (R,X_s,X_b) Without predictors\n",
    "data = mdata[['r','xs','xb']]\n",
    "dates = mdata['Date']\n",
    "data.index = dates\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Constant Expectated Return\n",
    "\n",
    "$$ y_{t+1} = \\mu + \\varepsilon_{t+1}, \\text{ with }\\varepsilon_{t+1} \\sim N(0,\\sigma^2) $$\n",
    "\n",
    "not to be confused with Certainty Equivalent Return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# CER (construct model)\n",
    "T = int(data.shape[0])\n",
    "n = int(data.shape[1])\n",
    "mu = np.mean(data,axis=0)\n",
    "# mu_temp = np.tile(mu.values,(int(data.shape[0]),1))\n",
    "# sigma = np.std(data-mu_temp)\n",
    "sigma = np.std(data)\n",
    "\n",
    "# simulate from the CER\n",
    "sim = [[0 for x in range(data.shape[1])] for k in range(0,data.shape[0])] \n",
    "for k in range(0,data.shape[0]):\n",
    "    sim[k][0] = mu[0] + np.random.normal(0,sigma[0]**2)\n",
    "    sim[k][1] = mu[1] + np.random.normal(0,sigma[1]**2)\n",
    "    sim[k][2] = mu[2] + np.random.normal(0,sigma[2]**2)\n",
    "\n",
    "tempdata = pd.DataFrame(sim)\n",
    "tempdata.columns = mdata.columns[1:4]\n",
    "tempdata.index = dates\n",
    "data = tempdata\n",
    "    \n",
    "# Write away the simulated data in order for it to be reused in each model\n",
    "# data.to_excel('sim_data_CER.xlsx', sheet_name='sheet1')    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector Autoregressive Model\n",
    "\n",
    "$$ y_{t+1} = B_0 + B_1 y_t + \\varepsilon_{t+1},\\text{ with }\\varepsilon_{t+1} \\sim N(0,\\sigma^2) $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# VAR\n",
    "dates = mdata['Date']\n",
    "data = mdata[['r','xs','xb']]\n",
    "data.index = pd.DatetimeIndex(dates)\n",
    "\n",
    "model = VAR(data[['r','xs','xb']])\n",
    "results = model.fit(1)   # fit a VAR(1) model on the data based on only the returns (no predictability)\n",
    "A = results.coefs\n",
    "\n",
    "results.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate from the VAR model and write away data\n",
    "sim = [[0 for x in range(mdata.shape[1]-1)] for k in range(0,mdata.shape[0])] \n",
    "eps = np.sqrt(np.var(results.resid)).values.reshape(1,3)\n",
    "x0 = np.random.normal(0,eps[0][0],mdata.shape[0])\n",
    "x1 = np.random.normal(0,eps[0][1],mdata.shape[0])\n",
    "x2 = np.random.normal(0,eps[0][2],mdata.shape[0])\n",
    "\n",
    "\n",
    "for k in range(0,mdata.shape[0]):\n",
    "    if k == 0:\n",
    "        Ahat = data[0:1].values.dot(A[0].transpose())\n",
    "        Ahat = Ahat[0]\n",
    "    else:\n",
    "        Ahat = np.array(np.array(sim[k-1]).dot(A[0].transpose()))\n",
    "    sim[k][0] = Ahat[0] + x0[k]\n",
    "    sim[k][1] = Ahat[1] + x1[k]\n",
    "    sim[k][2] = Ahat[2] + x2[k]\n",
    "\n",
    "tempdata = pd.DataFrame(sim)\n",
    "tempdata.columns = mdata.columns[1:4]\n",
    "tempdata.index = dates\n",
    "data = tempdata\n",
    "\n",
    "# Write away the simulated data in order for it to be reused in each model\n",
    "# data.to_excel('sim_data_VAR.xlsx', sheet_name='sheet1')    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Bayesian-VAR\n",
    "\n",
    "model: $ y_{t+1} = B_0 + B_1 y_t + \\varepsilon_{t+1}, \\varepsilon $\n",
    "\n",
    "The posterior distribution is given in the appendix of the paper of Bart Diris \n",
    "With the uniform prior it is as follows:\n",
    "\n",
    "$$ P(B,\\Sigma|Y) \\propto |\\Sigma|^{-(T+n+1)/2}\\exp \\left( -\\frac{1}{2}[(Y-XB')'(Y-XB')\\Sigma^{-1}]  \\right) I(B_1) $$\n",
    "\n",
    "This will be simulated with the help of the Gibbs sampler which on its turn will need the following conditional posteriors:\n",
    "\n",
    "$$ P(\\Sigma,\\beta,Y) = \\textit{iWishart}\\left((Y-XB')'(Y-XB'),T \\right), $$\n",
    "$$ P(\\beta,\\Sigma,Y) = N_{trunc}\\left(\\hat{\\beta},\\Sigma \\otimes (X'X)^{-1}\\right) $$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# BVAR\n",
    "\n",
    "# reformatting data\n",
    "Y = mdata[['r','xs','xb']]\n",
    "Y = np.asarray(Y) \n",
    "Y1 = np.roll(Y,1,axis=0)\n",
    "Y = np.delete(Y,(0),axis=0)\n",
    "Y1 = np.delete(Y1,(0),axis=0)\n",
    "T = Y.shape[0]\n",
    "n = Y.shape[1]\n",
    "X = np.column_stack([np.ones(T), Y1])\n",
    "\n",
    "#The gibbs sampler\n",
    "def gibbs(X,Y,N=2000,thin=100):\n",
    "    # initialize variables\n",
    "    Sigmalist = []\n",
    "    Blist = []\n",
    "    Sigma = np.zeros((n,n))\n",
    "    B = np.zeros((n,n+1))\n",
    "    \n",
    "    Y = np.matrix(Y)\n",
    "    X = np.matrix(X)\n",
    "    Sigma = np.zeros((n,n))\n",
    "    B = np.matrix(B)\n",
    "    \n",
    "    # Gibbs algorithm\n",
    "    for i in range(N):\n",
    "        # To make the series non dependent introduce a thinning\n",
    "        for j in range(thin):\n",
    "            # Draw random sample from an inverse Wishart distribution\n",
    "            Sigma = dist.invwishart.rvs(df=int(T),scale=((Y-X*B.T).T*(Y-X*B.T)))\n",
    "            # Draw random sample from the truncated multivariate normal distribution\n",
    "            Bhat = (X.T*X).I*(X.T*Y)\n",
    "            Btemp = Bhat.reshape((1,-1)).T\n",
    "            Btemp2 = [int(elem) for elem in Btemp]\n",
    "            ## TRUNCATED NORMAL (NOT INCLUDED NOW!!!)\n",
    "            B = np.random.multivariate_normal(Btemp2,np.kron(Sigma,(X.T*X).I)) \n",
    "            # reshape in order to remove the vectorization\n",
    "            B = B.reshape((n,n+1))\n",
    "            #Only after the burn-in period append the simulated values \n",
    "        if (i > 1000):\n",
    "            Sigmalist.append(Sigma)\n",
    "            Blist.append(B)\n",
    "    return Sigmalist,Blist\n",
    "\n",
    "Sigmalist, Blist = gibbs(X,Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Simulate from the BVAR model and write away data\n",
    "sim = [[0 for x in range(mdata.shape[1]-1)] for k in range(0,mdata.shape[0])] \n",
    "\n",
    "for k in range(0,mdata.shape[0]):\n",
    "    if k == 0:\n",
    "        Bhat = data[0:1].values.dot(Blist[0][:,1:4].transpose())\n",
    "        Bhat = Bhat[0] + Blist[0][:,0]\n",
    "    else:\n",
    "        Bhat = np.array(np.array(sim[k-1]).dot(Blist[k][:,1:4].transpose()))\n",
    "    eps = np.random.multivariate_normal([0,0,0],Sigmalist[k])\n",
    "    sim[k][0] = Bhat[0] + eps[0]\n",
    "    sim[k][1] = Bhat[1] + eps[1]\n",
    "    sim[k][2] = Bhat[2] + eps[2]\n",
    "    \n",
    "tempdata = pd.DataFrame(sim)\n",
    "tempdata.columns = mdata.columns[1:4]\n",
    "tempdata.index = dates\n",
    "data = tempdata\n",
    "\n",
    "# Write away the simulated data in order for it to be reused in each model\n",
    "# data.to_excel('sim_data_BVAR.xlsx', sheet_name='sheet1')    # already written away :)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model free benchmarks\n",
    "- 1\\N weight in each of the stocks\n",
    "- Full weight in one of the three stocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.16819349569\n",
      "1.04921534055\n",
      "1.40386946\n",
      "1.0823582681\n",
      "0.00443519011176\n",
      "5.82981011589e-05\n",
      "0.0157048370371\n",
      "0.00106715292668\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ny4wTv5lZZpz4zcwy83+mY8rVowvBMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x19d172b4e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Model-free benchmarks (1/N or full in the other assets)\n",
    "# index 239 is the beginning of the out-of-sample analysis 754 (last)\n",
    "a0 = [1/3,1/3,1/3]\n",
    "a1 = [1,0,0]\n",
    "a2 = [0,1,0]\n",
    "a3 = [0,0,1]\n",
    "\n",
    "r0list = []\n",
    "r1list = []\n",
    "r2list = []\n",
    "r3list = []\n",
    "\n",
    "for i in range(240,int(data.shape[0])-60):\n",
    "    r0 = 0\n",
    "    r1 = 0\n",
    "    r2 = 0\n",
    "    r3 = 0\n",
    "    for j in range(0,60):\n",
    "        s1 = data.iloc[i+j,0:4].values.reshape(1,3)\n",
    "        r0 += sum(a0*s1[0])\n",
    "        r1 += sum(a1*s1[0])\n",
    "        r2 += sum(a2*s1[0])\n",
    "        r3 += sum(a3*s1[0])\n",
    "    # transform from cumulative log return to Terminal wealth (given starting wealth is normalized to 1)\n",
    "    r0 = np.exp(r0)\n",
    "    r1 = np.exp(r1)\n",
    "    r2 = np.exp(r2)\n",
    "    r3 = np.exp(r3)\n",
    "    r0list.append(r0)\n",
    "    r1list.append(r1)\n",
    "    r2list.append(r2)\n",
    "    r3list.append(r3)\n",
    "    \n",
    "plt.plot(r0list)\n",
    "plt.plot(r1list)\n",
    "plt.plot(r2list)\n",
    "plt.plot(r3list)\n",
    "\n",
    "print(np.mean(r0list))\n",
    "print(np.mean(r1list))\n",
    "print(np.mean(r2list))\n",
    "print(np.mean(r3list))\n",
    "\n",
    "print(np.sqrt(np.var(r0list)))\n",
    "print(np.sqrt(np.var(r1list)))\n",
    "print(np.sqrt(np.var(r2list)))\n",
    "print(np.sqrt(np.var(r3list)))\n",
    "\n",
    "df = pd.DataFrame({'1/N':r0list, 'full r': r1list, 'full Xs':r2list,'full Xb':r3list, 'Date':mdata['Date'][240:(int(data.shape[0])-60)]})\n",
    "df.to_excel('Results_MF_Benchmark_CER.xlsx', sheet_name='sheet1')\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dynamic Strategy (Classical portfolio management)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "627\n",
      "1.24575113092\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.22222222  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "Writing away results\n",
      "628\n",
      "1.32207760766\n",
      "[ 0.          0.33333333  1.          0.          0.          0.77777778\n",
      "  0.77777778  0.          0.88888889  0.          0.          0.77777778\n",
      "  0.          0.66666667  0.11111111  0.22222222  0.          0.44444444\n",
      "  0.33333333  0.77777778  0.          1.          0.66666667  0.          0.\n",
      "  0.          0.          0.33333333  1.          0.55555556  1.          0.\n",
      "  0.          0.11111111  0.          0.          1.          0.          0.\n",
      "  0.          0.          0.88888889  0.          0.          0.22222222\n",
      "  0.          0.88888889  0.          0.55555556  0.          0.77777778\n",
      "  0.11111111  0.          0.33333333  0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Writing away results\n",
      "629\n",
      "1.13165343277\n",
      "[ 1.          0.33333333  1.          0.          1.          0.77777778\n",
      "  1.          1.          1.          1.          1.          0.          1.\n",
      "  1.          0.11111111  0.55555556  1.          0.88888889  0.          0.\n",
      "  0.          1.          0.55555556  1.          0.33333333  1.\n",
      "  0.22222222  0.55555556  0.88888889  0.77777778  0.11111111  0.55555556\n",
      "  0.          0.33333333  1.          0.22222222  0.55555556  0.88888889\n",
      "  0.44444444  1.          0.33333333  0.          0.88888889  0.          1.\n",
      "  1.          0.11111111  0.          1.          0.88888889  1.          1.\n",
      "  0.          0.33333333  0.          0.77777778  0.88888889  1.          0.        ]\n",
      "Writing away results\n",
      "630\n",
      "1.19500216887\n",
      "[ 1.          1.          0.77777778  1.          1.          1.          1.\n",
      "  1.          1.          0.66666667  0.55555556  1.          1.          1.\n",
      "  1.          0.66666667  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          0.88888889  1.          1.          1.          1.\n",
      "  1.          1.          1.          0.66666667  1.          0.88888889\n",
      "  1.          1.          1.          0.44444444  1.          0.44444444\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  0.77777778  0.44444444  1.          1.          0.88888889  1.        ]\n",
      "Writing away results\n",
      "631\n",
      "0.812125729562\n",
      "[ 1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.44444444\n",
      "  1.          1.          1.          1.          1.          0.66666667\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          0.77777778  0.88888889  0.33333333  0.          0.44444444\n",
      "  0.55555556  0.55555556  0.55555556  0.44444444  0.33333333  0.\n",
      "  0.11111111  0.          1.          0.          0.22222222  0.33333333\n",
      "  0.55555556  0.88888889  0.          0.77777778  1.          0.11111111\n",
      "  0.          0.          0.44444444  1.          0.33333333  0.88888889\n",
      "  0.          0.          0.33333333]\n",
      "Writing away results\n",
      "632\n",
      "0.91432842545\n",
      "[ 1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  0.88888889  1.          1.          1.          1.          1.          1.\n",
      "  1.          0.22222222  1.          0.88888889  1.          0.55555556\n",
      "  0.33333333  1.          0.22222222  1.          1.          1.          1.\n",
      "  0.77777778  0.33333333  0.          0.77777778  1.          0.55555556\n",
      "  0.          0.44444444  0.11111111  0.44444444  0.88888889  0.88888889\n",
      "  0.55555556  0.88888889  0.44444444  0.          1.          1.\n",
      "  0.33333333]\n",
      "Writing away results\n",
      "633\n",
      "0.994635219886\n",
      "[ 1.          1.          1.          0.55555556  0.77777778  1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.\n",
      "  0.88888889  1.          1.          0.55555556  1.          1.\n",
      "  0.66666667  1.          0.55555556  1.          0.77777778  1.\n",
      "  0.77777778  1.          1.          0.66666667  0.77777778  1.\n",
      "  0.22222222  1.          1.          1.          0.          1.\n",
      "  0.88888889  0.44444444  1.          1.          0.          0.          1.\n",
      "  0.          1.          1.          1.          0.          0.\n",
      "  0.55555556  0.        ]\n",
      "Writing away results\n",
      "634\n",
      "1.39111944404\n",
      "[ 0.          0.44444444  0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.66666667  0.          0.\n",
      "  0.11111111  0.33333333  0.22222222  0.          0.          1.\n",
      "  0.55555556  0.          0.          0.          0.          0.\n",
      "  0.88888889  0.33333333  0.          0.          0.          0.\n",
      "  0.11111111  0.          0.          0.          0.          0.          0.\n",
      "  1.          0.22222222  0.          0.44444444  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.33333333  0.          0.        ]\n",
      "Writing away results\n",
      "635\n",
      "1.0236559107\n",
      "[ 0.          0.          0.          0.11111111  0.          1.          0.\n",
      "  0.          0.          0.44444444  0.          1.          0.77777778\n",
      "  0.66666667  0.          1.          0.55555556  1.          0.\n",
      "  0.66666667  0.          0.77777778  1.          0.          0.77777778\n",
      "  0.11111111  0.77777778  0.22222222  0.55555556  0.66666667  1.\n",
      "  0.33333333  0.77777778  0.88888889  0.55555556  1.          0.11111111\n",
      "  0.          1.          0.33333333  0.22222222  0.          0.22222222\n",
      "  0.          0.          0.77777778  0.          0.          0.11111111\n",
      "  1.          1.          0.          0.          0.11111111  0.33333333\n",
      "  0.11111111  0.77777778  0.44444444  1.        ]\n",
      "Writing away results\n",
      "636\n",
      "1.24888994459\n",
      "[ 0.33333333  0.          1.          0.22222222  0.66666667  0.88888889\n",
      "  0.11111111  0.22222222  1.          1.          0.          0.55555556\n",
      "  1.          0.          0.66666667  0.11111111  1.          0.77777778\n",
      "  0.44444444  0.44444444  0.55555556  0.88888889  0.          0.44444444\n",
      "  0.44444444  0.          0.55555556  0.          0.77777778  0.\n",
      "  0.77777778  0.11111111  0.55555556  0.66666667  0.44444444  0.22222222\n",
      "  0.          1.          1.          0.          0.11111111  0.22222222\n",
      "  0.          1.          1.          0.          1.          0.88888889\n",
      "  0.11111111  0.88888889  0.          1.          0.          0.66666667\n",
      "  0.          0.88888889  0.44444444  0.          1.        ]\n",
      "Writing away results\n",
      "637\n",
      "1.42456729187\n",
      "[ 0.11111111  0.33333333  1.          0.88888889  0.11111111  0.          1.\n",
      "  0.22222222  0.88888889  0.11111111  0.22222222  1.          0.77777778\n",
      "  0.          0.33333333  0.          0.66666667  0.55555556  0.44444444\n",
      "  0.22222222  0.          0.55555556  0.          0.55555556  0.\n",
      "  0.66666667  0.44444444  1.          0.66666667  0.77777778  1.          0.\n",
      "  0.66666667  1.          1.          1.          0.33333333  0.77777778\n",
      "  1.          1.          1.          0.88888889  1.          0.88888889\n",
      "  1.          0.88888889  0.44444444  0.77777778  1.          1.\n",
      "  0.66666667  0.22222222  1.          1.          1.          1.          1.\n",
      "  1.          0.22222222]\n",
      "Writing away results\n",
      "638\n",
      "1.13653039928\n",
      "[ 1.          1.          1.          0.88888889  1.          1.          1.\n",
      "  1.          1.          0.55555556  1.          1.          1.          1.\n",
      "  0.44444444  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          0.66666667  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.        ]\n",
      "Writing away results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "639\n",
      "1.28671140852\n",
      "[ 0.11111111  0.          0.11111111  0.          0.          0.66666667\n",
      "  0.          0.11111111  0.77777778  0.11111111  0.          0.          0.\n",
      "  0.66666667  0.22222222  0.33333333  0.          0.44444444  0.22222222\n",
      "  1.          0.          0.55555556  0.22222222  0.55555556  1.          1.\n",
      "  0.66666667  1.          0.11111111  0.66666667  0.          0.44444444\n",
      "  0.66666667  0.22222222  0.66666667  1.          1.          0.          1.\n",
      "  0.88888889  1.          0.88888889  1.          1.          0.77777778\n",
      "  0.88888889  0.66666667  0.44444444  1.          1.          1.          1.\n",
      "  0.44444444  1.          1.          1.          1.          0.11111111\n",
      "  0.66666667]\n",
      "Writing away results\n",
      "640\n",
      "1.21213562004\n",
      "[ 0.          0.44444444  0.          0.          0.          0.          0.\n",
      "  0.55555556  0.          0.11111111  0.          0.          0.          0.\n",
      "  0.          0.55555556  0.          0.33333333  0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.55555556  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.        ]\n",
      "Writing away results\n",
      "641\n",
      "0.926642188955\n",
      "[ 1.          1.          0.          0.77777778  0.66666667  1.\n",
      "  0.77777778  0.44444444  0.77777778  0.          0.11111111  0.33333333\n",
      "  0.22222222  0.66666667  0.66666667  0.77777778  0.44444444  0.          0.\n",
      "  0.          0.          0.          0.          0.          0.55555556\n",
      "  0.22222222  0.          0.33333333  0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.33333333  0.          0.          0.\n",
      "  0.11111111  0.          0.          0.          0.          0.22222222\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.        ]\n",
      "Writing away results\n",
      "642\n",
      "1.16493259179\n",
      "[ 0.          1.          1.          0.66666667  1.          1.          1.\n",
      "  1.          1.          1.          1.          0.44444444  1.          1.\n",
      "  1.          1.          1.          0.33333333  1.          1.\n",
      "  0.77777778  1.          1.          1.          0.55555556  0.77777778\n",
      "  1.          1.          1.          1.          0.88888889  1.          1.\n",
      "  1.          0.66666667  0.55555556  1.          1.          0.77777778\n",
      "  1.          1.          1.          1.          1.          0.55555556\n",
      "  0.44444444  0.22222222  0.55555556  1.          1.          1.          1.\n",
      "  1.          0.55555556  0.77777778  1.          1.          0.44444444\n",
      "  0.88888889]\n",
      "Writing away results\n",
      "643\n",
      "1.26602828986\n",
      "[ 1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          0.55555556\n",
      "  0.66666667  1.          1.          0.66666667  1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          0.55555556  1.          1.          1.          1.          1.\n",
      "  1.          0.66666667  1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.66666667  1.\n",
      "  0.88888889  0.66666667  1.          1.          1.        ]\n",
      "Writing away results\n",
      "644\n",
      "1.09911258515\n",
      "[ 1.          1.          1.          1.          0.55555556  0.88888889\n",
      "  1.          1.          0.          1.          1.          1.\n",
      "  0.33333333  1.          0.66666667  1.          0.22222222  0.88888889\n",
      "  0.          0.          0.88888889  0.44444444  0.44444444  1.          1.\n",
      "  0.88888889  1.          1.          1.          1.          0.88888889\n",
      "  0.66666667  1.          1.          1.          1.          1.          1.\n",
      "  1.          1.          1.          1.          0.55555556  1.\n",
      "  0.88888889  1.          0.88888889  1.          0.77777778  1.          1.\n",
      "  1.          0.88888889  1.          1.          1.          1.          1.\n",
      "  1.        ]\n",
      "Writing away results\n",
      "645\n",
      "0.775850061385\n",
      "[ 1.          1.          0.11111111  1.          0.77777778  0.55555556\n",
      "  1.          0.77777778  1.          1.          0.88888889  1.          1.\n",
      "  0.55555556  1.          0.44444444  1.          0.          0.55555556\n",
      "  0.44444444  0.22222222  0.55555556  0.          0.44444444  0.11111111\n",
      "  1.          0.66666667  0.33333333  1.          1.          1.\n",
      "  0.66666667  0.55555556  1.          1.          1.          0.22222222\n",
      "  0.77777778  0.22222222  1.          1.          0.          1.          1.\n",
      "  1.          0.77777778  1.          0.44444444  0.66666667  0.55555556\n",
      "  0.33333333  0.66666667  0.55555556  1.          0.          0.\n",
      "  0.66666667  0.55555556  0.77777778]\n",
      "Writing away results\n",
      "646\n",
      "1.12891036817\n",
      "[ 0.          0.44444444  0.33333333  0.11111111  1.          0.55555556\n",
      "  0.77777778  0.66666667  0.66666667  0.          0.22222222  0.11111111\n",
      "  0.          0.22222222  0.          0.          0.          0.          1.\n",
      "  0.          0.22222222  0.          0.          0.44444444  0.          0.\n",
      "  0.          0.44444444  0.88888889  0.33333333  0.22222222  0.          0.\n",
      "  0.          0.          0.          0.          0.77777778  0.11111111\n",
      "  0.          0.          0.          0.          0.66666667  0.\n",
      "  0.11111111  0.          0.          0.          0.22222222  0.          0.\n",
      "  0.          0.          0.22222222  0.22222222  0.          1.          0.        ]\n",
      "Writing away results\n",
      "647\n",
      "1.11714960725\n",
      "[ 0.66666667  0.88888889  0.22222222  0.          0.          0.44444444\n",
      "  1.          0.          1.          0.55555556  0.77777778  0.\n",
      "  0.44444444  1.          0.          0.22222222  0.22222222  0.          0.\n",
      "  0.77777778  0.          0.          0.44444444  1.          0.55555556\n",
      "  0.22222222  0.55555556  0.          0.11111111  0.          0.33333333\n",
      "  0.44444444  0.66666667  0.88888889  0.          0.          0.22222222\n",
      "  0.          0.22222222  0.33333333  0.88888889  0.          0.          0.\n",
      "  0.          0.          0.          1.          0.          0.          0.\n",
      "  0.          0.          0.          0.22222222  0.66666667  0.\n",
      "  0.44444444  0.        ]\n",
      "Writing away results\n",
      "648\n",
      "1.30778445336\n",
      "[ 1.          0.88888889  0.55555556  0.          0.88888889  0.55555556\n",
      "  0.66666667  0.88888889  0.          0.33333333  1.          0.33333333\n",
      "  0.22222222  0.22222222  1.          0.55555556  0.          0.11111111\n",
      "  0.66666667  0.66666667  0.44444444  1.          0.          0.11111111\n",
      "  0.66666667  1.          0.          0.          0.          0.          0.\n",
      "  0.11111111  0.22222222  0.44444444  0.55555556  0.11111111  0.88888889\n",
      "  0.33333333  0.55555556  0.          0.          0.          0.88888889\n",
      "  0.          0.          0.          0.66666667  0.11111111  1.\n",
      "  0.11111111  0.          0.55555556  0.          0.66666667  0.\n",
      "  0.55555556  0.11111111  0.          0.11111111]\n",
      "Writing away results\n",
      "649\n",
      "1.37490519838\n",
      "[ 0.          0.          0.55555556  0.          0.          0.          0.\n",
      "  0.          0.          0.66666667  0.66666667  0.33333333  0.          0.\n",
      "  1.          0.77777778  0.11111111  0.66666667  1.          0.44444444\n",
      "  0.88888889  0.33333333  0.22222222  0.66666667  1.          0.88888889\n",
      "  1.          0.          0.11111111  0.22222222  0.88888889  1.          1.\n",
      "  0.77777778  0.55555556  1.          1.          0.55555556  1.          1.\n",
      "  0.          1.          0.44444444  0.77777778  0.88888889  1.\n",
      "  0.22222222  0.22222222  1.          0.          0.11111111  0.88888889\n",
      "  0.66666667  0.77777778  1.          0.11111111  0.55555556  1.\n",
      "  0.22222222]\n",
      "Writing away results\n",
      "650\n",
      "1.57519699031\n",
      "[ 0.          0.22222222  0.55555556  0.          0.          0.55555556\n",
      "  0.          0.88888889  0.          1.          1.          0.55555556\n",
      "  1.          1.          1.          1.          0.77777778  0.55555556\n",
      "  1.          0.          1.          0.33333333  0.77777778  1.\n",
      "  0.88888889  0.88888889  1.          1.          0.77777778  0.66666667\n",
      "  0.33333333  0.44444444  0.88888889  0.33333333  1.          0.          1.\n",
      "  0.77777778  0.88888889  0.88888889  1.          0.44444444  0.77777778\n",
      "  0.55555556  1.          0.44444444  0.33333333  0.33333333  0.11111111\n",
      "  1.          0.88888889  1.          0.55555556  1.          0.77777778\n",
      "  0.77777778  1.          0.66666667  1.        ]\n",
      "Writing away results\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "651\n",
      "2.22476040548\n",
      "[ 0.          0.          0.          0.44444444  0.          0.          0.\n",
      "  0.          0.11111111  0.44444444  0.66666667  0.33333333  0.44444444\n",
      "  0.77777778  0.55555556  1.          0.44444444  0.88888889  0.22222222\n",
      "  0.          1.          0.55555556  1.          0.77777778  0.55555556\n",
      "  1.          1.          0.55555556  1.          1.          0.44444444\n",
      "  1.          1.          0.          0.77777778  0.66666667  0.33333333\n",
      "  0.88888889  0.55555556  0.55555556  1.          0.88888889  0.\n",
      "  0.88888889  1.          0.11111111  0.77777778  0.          0.22222222\n",
      "  1.          0.55555556  0.88888889  0.55555556  1.          0.44444444\n",
      "  1.          1.          0.          0.88888889]\n",
      "Writing away results\n",
      "652\n",
      "1.27003399987\n",
      "[ 0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.33333333\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.          0.          0.          0.\n",
      "  0.          0.          0.          0.        ]\n",
      "Writing away results\n",
      "653\n"
     ]
    }
   ],
   "source": [
    "# Model benchmark (classical portfolio management) \n",
    "# expanding window + investment horizon = 5 years (K = 60)\n",
    "\n",
    "# parsing data\n",
    "dates = data.index\n",
    "mdata = data[['r','xs','xb']]\n",
    "mdata.index = pd.DatetimeIndex(dates)\n",
    "n = int(data.size/4-4)\n",
    "periods = 60\n",
    "simul = 400\n",
    "beginperiod = 241\n",
    "gamma = 2 #5 #2 \n",
    "TW = []\n",
    "MWeights = []\n",
    "Index = []\n",
    "Turnover = []\n",
    "RU = []\n",
    "totalRList = []\n",
    "totalOpimalWeights = []\n",
    "\n",
    "for i in range(627,700): #   n-periods-1): (possiblity to serialize) (Check 241 )\n",
    "    # initialization\n",
    "    optimalweights = np.zeros(periods-1)\n",
    "    currentK = 0\n",
    "    rList = []\n",
    "    print(i)\n",
    "    \n",
    "    while currentK < periods-1:\n",
    "        K = periods - currentK\n",
    "        \n",
    "        ## Simulate from the estimate VAR(1) model\n",
    "        model = VAR(mdata[0:i+currentK]) # take a smaller range to improve speed (like i - 200)\n",
    "        results = model.fit(1)   # fit a VAR(1) model on the data based on only the returns (no predictability)\n",
    "        A = results.coefs\n",
    "        sim = [[[0 for x in range(3)] for k in range(0,K)] for j in range(0,simul)]\n",
    "        for j in range(0,simul):\n",
    "            eps = np.sqrt(np.var(results.resid)).values.reshape(1,3)\n",
    "            x0 = np.random.normal(0,eps[0][0],K)\n",
    "            x1 = np.random.normal(0,eps[0][1],K)\n",
    "            x2 = np.random.normal(0,eps[0][2],K)\n",
    "\n",
    "            for k in range(0,K):\n",
    "                if k == 0:\n",
    "                    Ahat = mdata[i:i+1+currentK].values.dot(A[0].transpose())\n",
    "                    Ahat = Ahat[0]\n",
    "                else:\n",
    "                    Ahat = np.array(np.array(sim[j][k-1]).dot(A[0].transpose()))\n",
    "                sim[j][k][0] = Ahat[0] + x0[k]\n",
    "                sim[j][k][1] = Ahat[1] + x1[k]\n",
    "                sim[j][k][2] = Ahat[2] + x2[k]\n",
    "                \n",
    "        ## Calculate the optimal weights \n",
    "        W = np.linspace(0,1,10)\n",
    "        Ufut = np.ones(simul)\n",
    "        OptU = np.ones(simul)*-999\n",
    "        OptW = np.zeros(simul)\n",
    "        U = np.zeros(simul)\n",
    "\n",
    "        for k in range(1,K+1):\n",
    "            if k < K:\n",
    "                for w in W:\n",
    "                    for j in range(0,simul):\n",
    "                        U[j] = (1/(1-gamma))*(pow((w*np.exp(sim[j][K-k][1]) + (1-w)*np.exp(sim[j][K-k][2])),(1-gamma))*Ufut[j])\n",
    "                        # Eventually K-k-1 because now i calculate fut Utility of time period T+K+1\n",
    "                    slice = []\n",
    "                    for x in range(0,simul):\n",
    "                        slice.append(sim[x][K-k][1:3])\n",
    "                    slice = sm.add_constant(slice)\n",
    "                    olsmodel = sm.OLS(U, slice)\n",
    "                    CU = olsmodel.fit()\n",
    "#                     print(CU.params)\n",
    "                    CU = np.sum(slice * CU.params, axis=1)\n",
    "                    for j in range(0, simul):\n",
    "                        if CU[j] > OptU[j]:\n",
    "                            OptU[j] = CU[j]\n",
    "                            OptW[j] = w\n",
    "                slicexs = []\n",
    "                slicexb = []\n",
    "                for x in range(0,simul):\n",
    "                    slicexs.append(sim[x][K-k][1])\n",
    "                    slicexb.append(sim[x][K-k][2])\n",
    "                Ufut = (pow(OptW*np.exp(slicexs) + (1-OptW)*np.exp(slicexb),(1-gamma))*Ufut)\n",
    "#                 print(OptW*np.exp(slicexs))\n",
    "                OptU = np.ones(simul)*-999\n",
    "                OptW = np.zeros(simul)\n",
    "            else:\n",
    "                for w in W:\n",
    "                    for j in range(0,simul):\n",
    "                        U[j] = (1/(1-gamma))*((pow(w*np.exp(sim[j][K-k][1]) + (1-w)*np.exp(sim[j][K-k][2]),(1-gamma)))*Ufut[j])\n",
    "                    olsmodel = sm.OLS(U, np.ones(simul))\n",
    "                    CU = olsmodel.fit()\n",
    "                    CU = np.ones(simul) * CU.params\n",
    "                    for j in range(0, simul):\n",
    "                        if CU[j] > OptU[j]:\n",
    "                            OptU[j] = CU[j]\n",
    "                            OptW[j] = w\n",
    "        optimalweights[currentK] = OptW[1]\n",
    "        rtemp = optimalweights[currentK]*mdata[i+currentK:i+currentK+1]['xs']+(1-optimalweights[currentK])*mdata[i+currentK:i+currentK+1]['xb']\n",
    "        rList.append(rtemp.values)\n",
    "        currentK += 1\n",
    "        \n",
    "    totalOpimalWeights.append(optimalweights)\n",
    "    firstdiff = optimalweights[1:] - optimalweights[:-1]\n",
    "    # Calculate the Terminal Wealth from the given optimalweights  (Check whether indexes are right)\n",
    "    TerminalWealth = np.exp(sum(optimalweights*mdata[i+1:i+currentK+1]['xs'] + (1-optimalweights)*mdata[i+1:i+currentK+1]['xb']))\n",
    "    totalRList.append(rList)\n",
    "    TW.append(TerminalWealth)\n",
    "    # Mean of the weights\n",
    "    MWeights.append(np.mean(optimalweights))\n",
    "    # Index value in time\n",
    "    Index.append(i)\n",
    "    # Turnover\n",
    "    Turnover.append(sum(abs(firstdiff*np.exp(mdata[i+1:i+currentK]['xs'])) + abs((1-firstdiff)*np.exp(mdata[i+1:i+currentK]['xb']))))\n",
    "    # Realized Utility\n",
    "    RU.append((1/(1-gamma))*pow(TerminalWealth,(1-gamma)))\n",
    "    \n",
    "    print(TerminalWealth)\n",
    "    print(optimalweights)\n",
    "    \n",
    "    print('Writing away results')  # Writes away mostly the same data every time, this is done so the run can be interrupted without losing results\n",
    "    #     df = pd.DataFrame({'index date':Index,'TW':TW, 'Mean Weights Xs':MWeights})\n",
    "    df = pd.DataFrame({'index date':Index,'TW':TW, 'Mean Weights Xs':MWeights,'Turnover':Turnover, 'Realized Utility':RU, 'Returns':totalRList, 'Optimal Weights':totalOpimalWeights})\n",
    "    df.to_excel('REAL_gamma2_ReturnsWeights_627-700.xlsx', sheet_name='sheet1', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
