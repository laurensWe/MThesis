{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "from random import randint\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mdata = pd.read_csv('data.csv') #Three stocks (R,X_s,X_b) Without predictors\n",
    "mdata = np.array(mdata[['r','xs','xb']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "226\n"
     ]
    }
   ],
   "source": [
    "#hyperparams\n",
    "\n",
    "series_length = 15\n",
    "total_series_length = 241-series_length\n",
    "batch_size = 1\n",
    "truncated_backprop_length = series_length//batch_size\n",
    "state_size = 4\n",
    "num_classes = 10\n",
    "echo_step = 3\n",
    "num_batches = total_series_length//batch_size//truncated_backprop_length\n",
    "num_stocks = 3\n",
    "print(total_series_length//batch_size)\n",
    "gamma = 1 \n",
    "train_data = 241 # also an expanding window\n",
    "jList = []\n",
    "TWlistTrain = []\n",
    "TWlist = []\n",
    "Index = []\n",
    "MWeights = []\n",
    "epsilon = 0.1\n",
    "n = mdata.size/4-4\n",
    "periods = 60\n",
    "epochs = 3\n",
    "TC = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def generateData():\n",
    "    begin_idx = randint(0,total_series_length)\n",
    "    x = mdata.transpose()\n",
    "    x = x[0:3,begin_idx:begin_idx+series_length]\n",
    "    y = np.roll(x, echo_step, axis=1)\n",
    "    y[:,0:echo_step] = 0 \n",
    "    \n",
    "    x = x.reshape((num_stocks, batch_size, -1))  \n",
    "    y = y.reshape((num_stocks, batch_size, -1))\n",
    "    return (x, y)\n",
    "\n",
    "data = generateData()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Initialize Recurrent Neural Network and set-up the placeholders\n",
    "tf.reset_default_graph()\n",
    "NN_input = tf.placeholder(tf.float32, [num_stocks, batch_size, truncated_backprop_length])\n",
    "init_state = tf.placeholder(tf.float32, [num_stocks, batch_size, state_size])\n",
    "Q_Next = tf.placeholder(tf.float32, [truncated_backprop_length, batch_size, num_classes])\n",
    "\n",
    "# Weights and biases\n",
    "W = tf.Variable(np.random.rand(num_stocks, state_size+1, state_size), dtype=tf.float32)\n",
    "b = tf.Variable(np.zeros((num_stocks,1,state_size)), dtype=tf.float32)\n",
    "W2 = tf.Variable(np.random.rand(num_stocks, state_size, num_classes),dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((num_stocks, 1,num_classes)), dtype=tf.float32)\n",
    "\n",
    "inputs_series = tf.unstack(NN_input, axis=2)\n",
    "labels_series = tf.unstack(Q_Next, axis=0)\n",
    "\n",
    "#Forward pass\n",
    "current_state = init_state\n",
    "states_series = []\n",
    "\n",
    "for current_input in inputs_series:\n",
    "    current_input = tf.reshape(current_input, [num_stocks,batch_size, 1])\n",
    "    input_and_state_concatenated = tf.concat([current_input, current_state],axis=2)  # Increasing number of columns\n",
    "    next_state = tf.tanh(tf.matmul(input_and_state_concatenated,W) + b)  # Broadcasted addition\n",
    "    states_series.append(next_state)\n",
    "    current_state = next_state\n",
    "\n",
    "#calculate loss\n",
    "Q_FA = [tf.matmul(state, W2) + b2 for state in states_series]\n",
    "Q_FA = tf.reduce_sum(Q_FA,axis=1)\n",
    "A_Max = tf.argmax(Q_FA[-1],1) # only use the latest Q of the RNN for the determination of the optimal weights\n",
    "Q_series = tf.unstack(Q_FA, axis=0)\n",
    "\n",
    "# Calculate loss for the NN from the Q values\n",
    "losses = [ abs(logits - labels) for logits, labels in zip(Q_series,labels_series)]\n",
    "total_loss = tf.reduce_mean(losses)\n",
    "# loss = tf.reduce_sum(tf.square(Q_Next - Q_FA))\n",
    "trainer = tf.train.GradientDescentOptimizer(learning_rate=0.1)\n",
    "updateModel = trainer.minimize(total_loss)\n",
    "\n",
    "#Define Action Matrix (Now discrete case) \n",
    "A = np.linspace(0,1,10) # portfolio weights of stocks (1-weight) is the weight in the bonds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n",
      "Writing away results\n",
      "242\n",
      "Writing away results\n",
      "243\n",
      "Writing away results\n",
      "244\n",
      "Writing away results\n",
      "245\n",
      "Writing away results\n",
      "246\n",
      "Writing away results\n",
      "247\n",
      "Writing away results\n",
      "248\n",
      "Writing away results\n",
      "249\n",
      "Writing away results\n",
      "250\n",
      "Writing away results\n",
      "251\n",
      "Writing away results\n",
      "252\n",
      "Writing away results\n",
      "253\n",
      "Writing away results\n",
      "254\n",
      "Writing away results\n",
      "255\n",
      "Writing away results\n",
      "256\n",
      "Writing away results\n",
      "257\n",
      "Writing away results\n",
      "258\n",
      "Writing away results\n",
      "259\n",
      "Writing away results\n",
      "260\n",
      "Writing away results\n",
      "261\n",
      "Writing away results\n",
      "262\n",
      "Writing away results\n",
      "263\n",
      "Writing away results\n",
      "264\n",
      "Writing away results\n",
      "265\n",
      "Writing away results\n",
      "266\n",
      "Writing away results\n",
      "267\n",
      "Writing away results\n",
      "268\n",
      "Writing away results\n",
      "269\n",
      "Writing away results\n",
      "270\n",
      "Writing away results\n",
      "271\n",
      "Writing away results\n",
      "272\n",
      "Writing away results\n",
      "273\n",
      "Writing away results\n",
      "274\n",
      "Writing away results\n",
      "275\n",
      "Writing away results\n",
      "276\n",
      "Writing away results\n",
      "277\n",
      "Writing away results\n",
      "278\n",
      "Writing away results\n",
      "279\n",
      "Writing away results\n",
      "280\n",
      "Writing away results\n",
      "281\n",
      "Writing away results\n",
      "282\n",
      "Writing away results\n",
      "283\n",
      "Writing away results\n",
      "284\n",
      "Writing away results\n",
      "285\n",
      "Writing away results\n",
      "286\n",
      "Writing away results\n",
      "287\n",
      "Writing away results\n",
      "288\n",
      "Writing away results\n",
      "289\n",
      "Writing away results\n",
      "290\n",
      "Writing away results\n",
      "291\n",
      "Writing away results\n",
      "292\n",
      "Writing away results\n",
      "293\n",
      "Writing away results\n",
      "294\n",
      "Writing away results\n",
      "295\n",
      "Writing away results\n",
      "296\n",
      "Writing away results\n",
      "297\n",
      "Writing away results\n",
      "298\n",
      "Writing away results\n",
      "299\n",
      "Writing away results\n",
      "300\n",
      "Writing away results\n",
      "301\n",
      "Writing away results\n",
      "302\n",
      "Writing away results\n",
      "303\n",
      "Writing away results\n",
      "304\n",
      "Writing away results\n",
      "305\n",
      "Writing away results\n",
      "306\n",
      "Writing away results\n",
      "307\n",
      "Writing away results\n",
      "308\n",
      "Writing away results\n",
      "309\n",
      "Writing away results\n",
      "310\n",
      "Writing away results\n",
      "311\n",
      "Writing away results\n",
      "312\n",
      "Writing away results\n",
      "313\n",
      "Writing away results\n",
      "314\n",
      "Writing away results\n",
      "315\n",
      "Writing away results\n",
      "316\n",
      "Writing away results\n",
      "317\n",
      "Writing away results\n",
      "318\n",
      "Writing away results\n",
      "319\n",
      "Writing away results\n",
      "320\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 756 is out of bounds for axis 0 with size 755",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-12ce41cfda06>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     59\u001b[0m         \u001b[1;31m# For insight purposes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[0mMWeights\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOptimalWeights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mcurrentK\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m+\u001b[0m\u001b[0mtruncated_backprop_length\u001b[0m\u001b[1;33m+\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[0mTWlist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mOptimalWeights\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mOptimalWeights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m         \u001b[0mIndex\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 756 is out of bounds for axis 0 with size 755"
     ]
    }
   ],
   "source": [
    "TWlist = []\n",
    "Index = []\n",
    "MWeights = []\n",
    "\n",
    "with tf.Session() as sess:\n",
    "    for i in range(241,int(n-periods-1)):\n",
    "        OptimalWeights = np.zeros(periods-1)\n",
    "        currentK = 0;\n",
    "        print(i)\n",
    "        sess.run(tf.global_variables_initializer()) # initialize the Neural Network again\n",
    "        \n",
    "        while currentK < periods - 1:\n",
    "            #Initilization\n",
    "            NN_data = mdata[0:i+currentK]  # rolling window\n",
    "            #initialize an empty hidden state\n",
    "            _current_state = np.zeros((num_stocks, batch_size, state_size))\n",
    "            # NN_data = mdata[0:i+currentK]   #Expanding window\n",
    "            rAll = 0\n",
    "            currentEpoch = 0\n",
    "            \n",
    "            while currentEpoch < epochs:\n",
    "                a_old = 0\n",
    "                #Training of the Q-Network for the data available (with Neural Nets) \n",
    "                for j in range(0,len(NN_data)-truncated_backprop_length-1):\n",
    "                    s = NN_data[j:j+truncated_backprop_length,0:3].reshape(num_stocks,batch_size,truncated_backprop_length)\n",
    "                    #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                    \n",
    "                    # INITIALIZE THE PLACEHOLDERS\n",
    "                    a_int,allQ = sess.run([A_Max,Q_FA],feed_dict={NN_input:s, init_state:_current_state})\n",
    "                    a = A[a_int-1]  # -1 because the output neurons are labeled 1 till 101 and it will be an index\n",
    "                    if np.random.rand(1) < epsilon:\n",
    "                        a = random.choice(A)\n",
    "\n",
    "                    #Get new state and reward from environment\n",
    "                    s1 = NN_data[j+truncated_backprop_length:j+truncated_backprop_length+1,1:4]\n",
    "#                     s1 = mdata[i+currentK+j+truncated_backprop_length+1,1:4]\n",
    "                    r = (a*s1[0][0] + (1-a)*s1[0][1] - TC*abs(a_old-a) ) #reward: this is now the wealth gained from this step, but could be other rewards like utility\n",
    "                    a_old = a\n",
    "                    s1 = NN_data[j+1:j+truncated_backprop_length+1,0:3].reshape(num_stocks,batch_size,truncated_backprop_length)\n",
    "                    Q = sess.run(Q_FA,feed_dict={NN_input:s1, init_state:_current_state})\n",
    "        \n",
    "                    #Obtain maxQ' and set our target value for chosen action.\n",
    "                    Q1 = np.max(Q[-1])\n",
    "                    targetQ = allQ\n",
    "                    targetQ[-1,0,a_int] = r + gamma*Q1\n",
    "\n",
    "                    #Train the neural network using target and predicted Q values\n",
    "                    # INITIALIZE THE PLACEHOLDERS\n",
    "                    _,_current_state,W1 = sess.run([updateModel,current_state,NN_input],feed_dict={NN_input:s,Q_Next:targetQ, init_state:_current_state})\n",
    "                currentEpoch += 1\n",
    "        \n",
    "            # After training now calculate the optimal weights for the K=60 periods to come\n",
    "            s1 = NN_data[j+1:j+truncated_backprop_length+1,0:3].reshape(num_stocks,batch_size,truncated_backprop_length)\n",
    "            a_int,allQ = sess.run([A_Max,Q_FA],feed_dict={NN_input:s, init_state:_current_state})\n",
    "            aOpt = A[a_int-1]\n",
    "            OptimalWeights[currentK] = aOpt\n",
    "            currentK += 1\n",
    "        \n",
    "        # For insight purposes\n",
    "        MWeights.append(np.mean(OptimalWeights))\n",
    "        x = mdata[i+currentK+j+truncated_backprop_length+1,1:4]\n",
    "        TWlist.append(np.exp(sum(OptimalWeights*x[0] + (1-OptimalWeights)*x[1])))\n",
    "        Index.append(i)\n",
    "        \n",
    "        print('Writing away results')\n",
    "        df = pd.DataFrame({'index date':Index,'TW':TWlist, 'Mean Weights Xs':MWeights})\n",
    "        df.to_excel('Results_ExpRNN_g10_Other_TC_e3.xlsx', sheet_name='sheet1', index=False)\n",
    "    # close session\n",
    "plt.plot(MWeights)\n",
    "plt.plot(TWlist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
