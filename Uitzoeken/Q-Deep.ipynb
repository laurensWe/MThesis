{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reinforcement Q-learning simple NN as function approximation\n",
    "\n",
    "- portfolio grid of size 10 (0 to 1)\n",
    "- 1 hidden neural layers \n",
    "- Improved by Dropout "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Initialization\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import winsound"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('data.csv') #Three stocks (R,X_s,X_b,s_nom,s_pe,s_spr) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_excel('sim_data_CER.xlsx') #Three stocks (R,X_s,X_b) Without predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialization of the Tensorflow placeholders and the network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_lags = 11\n",
    "num_stocks=3\n",
    "num_inputvar = (num_lags+1)*num_stocks\n",
    "num_actions=10\n",
    "hidden1 = 60\n",
    "hidden2 = 45\n",
    "hidden3 = 20\n",
    "\n",
    "#Initialize Neural Network and set-up the placeholders\n",
    "tf.reset_default_graph()\n",
    "NN_input = tf.placeholder(shape=[1,num_inputvar],dtype=tf.float32)\n",
    "w1 = tf.Variable(tf.random_uniform([num_inputvar,hidden1],0,1))\n",
    "w2 = tf.Variable(tf.random_uniform([hidden1,hidden2],0,1))\n",
    "w3 = tf.Variable(tf.random_uniform([hidden2,hidden3],0,1))\n",
    "w4 = tf.Variable(tf.random_uniform([hidden3,num_actions],0,1))\n",
    "b1 = tf.Variable(np.zeros((1,hidden1)), dtype=tf.float32)\n",
    "b2 = tf.Variable(np.zeros((1,hidden2)), dtype=tf.float32)\n",
    "b3 = tf.Variable(np.zeros((1,hidden3)), dtype=tf.float32)\n",
    "b4 = tf.Variable(np.zeros((1,num_actions)), dtype=tf.float32)\n",
    "\n",
    "h1 = tf.add(tf.matmul(NN_input,w1),b1)\n",
    "h_drop1 = tf.nn.dropout(h1,0.5)\n",
    "a1 = tf.nn.relu(h_drop1)\n",
    "\n",
    "h2 = tf.add(tf.matmul(a1,w2),b2)\n",
    "h_drop2 = tf.nn.dropout(h2,0.3)\n",
    "a2 = tf.nn.relu(h_drop2)\n",
    "\n",
    "h3 = tf.add(tf.matmul(a2,w3),b3)\n",
    "h_drop3 = tf.nn.dropout(h3,0.1)\n",
    "a3 = tf.nn.relu(h_drop3)\n",
    "\n",
    "ol = tf.add(tf.matmul(a3,w4),b4)\n",
    "output = tf.nn.softmax(ol)\n",
    "\n",
    "A_Max = tf.argmax(output,1)\n",
    "# Calculate loss for the NN from the Q values\n",
    "Q_Next = tf.placeholder(shape=[1,num_actions],dtype=tf.float32)\n",
    "diff = tf.subtract(Q_Next,output)\n",
    "loss = tf.reduce_sum(tf.multiply(diff,diff))\n",
    "learning_rate = tf.placeholder(tf.float32, shape=[])\n",
    "# cross_entropy = tf.reduce_mean(-tf.reduce_sum(a4 * tf.log(Q_Next), reduction_indices=[1]))\n",
    "optmzr = tf.train.GradientDescentOptimizer(learning_rate = learning_rate).minimize(loss)\n",
    "A = np.linspace(0,1,num_actions) # portfolio weights of stocks (1-weight) is the weight in the bonds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training of the NN function approximation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "241\n"
     ]
    }
   ],
   "source": [
    "# initialize\n",
    "init = tf.global_variables_initializer()\n",
    "startepsilon = 0.8\n",
    "endepsilon = 0.01\n",
    "startlr = 0.8\n",
    "endlr = 0.01\n",
    "startgamma = 0.01\n",
    "endgamma = 0.8\n",
    "TWlist = []\n",
    "Index = []\n",
    "MWeights = []\n",
    "Turnover = []\n",
    "chooserlist = []\n",
    "RU = []\n",
    "learningrateQ = 0.8\n",
    "n = 707\n",
    "periods = 2\n",
    "epochs = 50     # preferred to have a low amount of epochs because otherwise the the same data is used multiple times (usually not the case in stock returns)\n",
    "\n",
    "# data parsing\n",
    "dates = data['Date']\n",
    "mdata = data[['r','xs','xb']]\n",
    "mdata.index = pd.DatetimeIndex(dates)\n",
    "\n",
    "# include the lags\n",
    "for i in range(1,num_lags+1):  # 1 till 11\n",
    "    mdata['r_lag' + str(i)] = mdata['r'].shift(i)\n",
    "    mdata['xs_lag' + str(i)] = mdata['xs'].shift(i)\n",
    "    mdata['xb_lag' + str(i)] = mdata['xb'].shift(i)\n",
    "\n",
    "mdata.drop(mdata.head(num_lags).index, inplace=True)\n",
    "# have a look at the data (if not include NANs)\n",
    "# print(mdata)\n",
    "\n",
    "# Train the the Q-function DNN\n",
    "with tf.Session() as sess:\n",
    "    for i in range(241,int(n-periods-1)):\n",
    "        lostlist = []\n",
    "        OptimalWeights = np.zeros(periods-1)\n",
    "        currentK = 0\n",
    "        print(i)\n",
    "        rstd = 1\n",
    "        rmean = 0\n",
    "        \n",
    "        while currentK < periods - 1:\n",
    "            epsilon = 0.15\n",
    "            lr = 0.00003\n",
    "            gamma = 0.5\n",
    "            sess.run(init) # initialize the Neural Network again\n",
    "            currentEpoch = 0\n",
    "            rlist = []               \n",
    "            indexes = np.asarray(range(i+currentK-1)) \n",
    "            \n",
    "            while currentEpoch < epochs:\n",
    "#                 if(currentEpoch > 0):\n",
    "#                     epsilon -= (startepsilon-endepsilon)/epochs\n",
    "#                     lr -= (startlr-endlr)/epochs\n",
    "#                     gamma += (startgamma-endgamma)/epochs\n",
    "                    \n",
    "                #Training of the Q-Network for the data available (with Neural Nets) \n",
    "                for j in indexes:\n",
    "                    s = mdata.iloc[j,:].values.reshape(1,num_inputvar)\n",
    "                    #Choose an action by greedily (with e chance of random action) from the Q-network\n",
    "                    a_int,allQ = sess.run([A_Max,output],feed_dict={NN_input:s})\n",
    "                    a = A[a_int-1]  # -1 because index\n",
    "                    if np.random.rand(1) < epsilon:\n",
    "                        a = random.choice(A)\n",
    "\n",
    "                    #Get new state and reward from environment\n",
    "                    s1 = mdata.iloc[j+1,:].values.reshape(1,num_inputvar)\n",
    "                    r = (a*s1[0][1] + (1-a)*s1[0][2]) #reward: this is now the wealth gained from this step, but could be other rewards like utility\n",
    "                    rlist.append(r)\n",
    "                    Q = sess.run(output,feed_dict={NN_input:s1})\n",
    "                    \n",
    "                    #Obtain maxQ' and set our target value for chosen action.\n",
    "                    Q1 = np.max(Q)\n",
    "                    targetQ = allQ\n",
    "                    if(len(rlist)>1):\n",
    "                        rstd = np.std(rlist)\n",
    "                        rmean = np.mean(rlist)\n",
    "                    targetQ[0,int(a*(num_actions-1))] = targetQ[0,int(a*(num_actions-1))] + learningrateQ*((r-rmean)/rstd + gamma*Q1 - targetQ[0,int(a*(num_actions-1))])\n",
    "#                     targetQ[0,int(a*(num_actions-1))] = targetQ[0,int(a*(num_actions-1))] + learningrateQ*(r + gamma*Q1 - targetQ[0,int(a*(num_actions-1))]) \n",
    "#                     targetQ[0,int(a*(num_actions-1))] = r + gamma*Q1\n",
    "#                     rlist.append(r)\n",
    "                    #Train the neural network using target and predicted Q values\n",
    "                    opt,W1,loss_ = sess.run([optmzr,w1,loss],feed_dict={NN_input:s,Q_Next:targetQ,learning_rate:lr})\n",
    "                    lostlist.append(loss_)\n",
    "                currentEpoch += 1\n",
    "            \n",
    "            # After training now calculate the optimal weights for the K=60 periods to come\n",
    "            s = mdata.iloc[i+currentK,:].values.reshape(1,num_inputvar)\n",
    "            a_int,allQ = sess.run([A_Max,output],feed_dict={NN_input:s})\n",
    "            aOpt = A[a_int-1]\n",
    "            OptimalWeights[currentK] = aOpt\n",
    "            currentK += 1\n",
    "            \n",
    "        # For insight purposes (Write away)\n",
    "        plt.ion()\n",
    "        plt.plot(lostlist)\n",
    "        plt.show()\n",
    "        plt.plot(rlist)\n",
    "        plt.show()\n",
    "        \n",
    "        firstdiff = OptimalWeights[1:] - OptimalWeights[:-1]\n",
    "        MWeights.append(np.mean(OptimalWeights))\n",
    "        TerminalWealth = np.exp(sum(OptimalWeights*mdata[i+1:i+currentK+1]['xs'] + (1-OptimalWeights)*mdata[i+1:i+currentK+1]['xb']))\n",
    "        TWlist.append(TerminalWealth)\n",
    "        Index.append(i)\n",
    "        Turnover.append(sum(abs(firstdiff*np.exp(mdata[i+1:i+currentK]['xs'])) + abs((1-firstdiff)*np.exp(mdata[i+1:i+currentK]['xb']))))\n",
    "        RU.append((1/(1-5))*pow(TerminalWealth,(1-5)))\n",
    "        print(OptimalWeights)\n",
    "        print(TerminalWealth)\n",
    "        \n",
    "        # Make a sound when done\n",
    "#         duration = 1000  # millisecond\n",
    "#         freq = 440  # Hz\n",
    "#         winsound.Beep(freq, duration)\n",
    "        \n",
    "        print('Writing away results')\n",
    "        df = pd.DataFrame({'index date':Index,'TW':TWlist, 'Mean Weights Xs':MWeights,'Turnover':Turnover, 'Realized Utility':RU})\n",
    "        df.to_excel('DNN_2.xlsx', sheet_name='sheet1', index=False)\n",
    "print('Done!')\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
